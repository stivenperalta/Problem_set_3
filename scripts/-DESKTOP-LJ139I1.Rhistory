html_table()
sample1 %>%
html_table()
html_sample1 %>%
html_table()
table1 <- read_html("https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css")
table1
view(table1)
as.data.frame(table1)
tabla1 %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
tabla1 <- read_html("https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
tabla1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html") %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
texto <- html_text(nodos)
tabla1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html") %>%
html_table()
tabla1
view(tabla1)
rm(list = ls()) # Limpiar Rstudio
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
rm(list = ls()) # Limpiar Rstudio
options(scipen = 20,  digits=1)
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
rm(list = ls()) # Limpiar Rstudio
options(scipen = 20,  digits=1)
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
table1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html") %>%
html_table()
head(tabla1)
head(table1)
title(table1)
names(table1)
as.data.frame(table1)
names(table1)
?for
for (variable in vector) {
?for
d
for?
data_base <- ("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_") %>%
for (i in 1:10) {
datai <- paste0(data_base, i, ".html")
}
data_base <- ("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_")
head(data_base)
for (i in 1:10) {
datai <- paste0(data_base, i, ".html")
}
# creo un loop para descargar las 10 bases de datos
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
numero_inicial <- 1
numero_final <- 10
for (i in numero_inicial:numero_final) {
url <- paste0(url_base, i, ".html")
pagina <- read_html(url)
}
head(i)
view(i)
paginai <- read_html(url) %>%
html_table()
# creo un loop para descargar las 10 bases de datos
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
paginai <- read_html(url)
html_table()
}
paginai <- read_html(url)
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
paginai <- read_html(url)
}
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
read_html(url)
}
head(url)
citation()
citation("rvest")
citation("car ")
citation("car")
install.packages(c("cpp11", "dbplyr", "digest", "future", "gargle", "haven", "jsonlite", "lme4", "pkgload", "pROC", "processx", "Rcpp", "readxl", "rmarkdown", "rstudioapi", "shiny", "testthat", "vctrs", "webshot", "xml2"))
q()
# Classification ##########################################################
rm(list = ls())
pacman::p_load(tydiverse)
getwd()
pacman::p_load(tydiverse)
pacman::p_load(tidyverse)
getwd()
getwd()
getwd()
getwd()
rm(list = ls()) # Limpiar Rstudio
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
glimpse(train) # visualizamos los datos
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
table(train$pobre) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
33024/164960
# Creo control por valicación cruzada
cv<-trainControl(method="cv",
number=5,
classProbs=TRUE, #retorna la probabilidad de cada una de las clases
verbose=TRUE, #
savePredictions=T) #que guarde las predicciones
glimpse(train)
train_1 <- train %>%
select(-pobre)
test_1 <- test %>%
select(-pobre)
mod_rf_1 <- train(
IngresoPerCapita ~ .,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
test_1 <- test %>%
select(-pobre)
#omito variable de interés binaria para la estimación
train_1 <- train %>%
select(-pobre)
# selecciono variables de mayor interés
train_1 <- select(train)
names(train)
# selecciono variables de mayor interés
train_1 <- select(train, c(1:9, 13:23, 25:48))
test_1 <- select(test, c(1:9, 13:23, 25:48))
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
mod_rf_1 <- train(
pobre ~ . - id - IngresoPerCapita,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
names(train_1)
mod_rf_1 <- train(
pobre ~ . - id - IngresoPerCapita,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
glimpse(train) # visualizamos los datos
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
table(train$pobre) #los datos estan desbalanceados
table.pro(table(train$pobre)) #los datos estan desbalanceados
table.per(table(train$pobre)) #los datos estan desbalanceados
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
prop.table(table(train$pobre)) #los datos estan desbalanceados
# selecciono variables de mayor interés
train_1 <- select(train, c(1:9, 13:23, 25:48))
test_1 <- select(test, c(1:9, 13:23, 25:48))
# Creo control por valicación cruzadamod_fr_1$bestTune
cv<-trainControl(method="cv",
number=5,
classProbs=TRUE, #retorna la probabilidad de cada una de las clases
verbose=TRUE, #
savePredictions=T) #que guarde las predicciones
names(train)
# selecciono variables de mayor interés
train <- select(train, c(1:9, 13:23, 25:48))
test <- select(test, c(1:9, 13:23, 25:48))
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
rm(list = ls()) # Limpiar Rstudio
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
# selecciono variables de mayor interés
train <- select(train, c(1:9, 13:23, 25:48))
test <- select(test, c(1:9, 13:23, 25:48))
glimpse(train) # visualizamos los datos
names(train)
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
train<-readRDS("../stores/train_final.rds")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test_1_1<-readRDS("../stores/test_1_final.rds")
#Importamos las bases
test<-readRDS("../stores/test_1_final.rds")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
# selecciono variables de mayor interés
train <- select(train, c(1:6, 8, 9, 13:24, 25:44, 47, 48))
test <- select(test, c(1:6, 8, 9, 13:24, 25:44, 47, 48))
names(train)
glimpse(train)
summary(train)
table(cuartos$hogar)
table(train$cuartos_hog)
table(train$cuartos_dorm)
table(train$Jefe_hogar)
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
names(train)
summary(train)
prop.table(table(train$d_arriendo))
glimpse(train)
View(train)
#convertimos en factor
as.factor(train$Regimen_salud)
summary(train)
#convertimos en factor
train$Regimen_salud <- as.factor(train$Regimen_salud)
summary(train)
test$Regimen_salud <- as.factor(test$Regimen_salud)
names(train)
summary(train)
train$Antiguedad_trabajo <- as.factor(train$Antiguedad_trabajo)
test$Antiguedad_trabajo <- as.factor(test$Antiguedad_trabajo)
summary(train)
names(train)
# selecciono variables de mayor interés
train <- select(train, c(1:6, 13:14, 16, 17, 19:24, 26, 44, 47, 48, 8, 9))
test <- select(test, c(1:6, 13:14, 16, 17, 19:24, 26, 44, 47, 48, 8, 9))
summary(train)
table(train$Li)
# Creo control por valicación cruzadamod_fr_1$bestTune
cv<-trainControl(method="cv",
number=5,
classProbs=TRUE, #retorna la probabilidad de cada una de las clases
verbose=TRUE, #
savePredictions=T) #que guarde las predicciones
names(train)
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train,
method = "ranger",
trControl = cv,
maximize = F
)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train,
method = "rpart",
trControl = cv
)
# random forest clasificación
mod_rf_1 <- train(
pobre ~ . - id - IngresoPerCapita -Li -Lp,
data = train,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC, randomForest, caret) # Cargar paquetes requeridos
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC, randomForest) # Cargar paquetes requeridos
# Creo control por valicación cruzadamod_fr_1$bestTune
cv<-trainControl(method="cv",
number=5)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train,
method = "rpart",
trControl = cv
)
names(train)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + nper + Nivel_educativo + Tipodevivienda, #- id - pobre -Li -Lp
data = train,
method = "rpart",
trControl = cv
)
summary(train)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + nper + Nivel_educativo + Tipodevivienda, #- id - pobre -Li -Lp
data = train,
method = "rpart"
#  trControl = cv
)

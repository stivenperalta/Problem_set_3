glimpse(train)
set.seed(2023)
nb1 <- train(pobre ~ cuartos_dorm+ nper +Porcentaje_ocupados + v.cabecera
+ Jefe_mujer+ Tipodevivienda +edad
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo ,
data = train,
method = "nb",
trControl = ctrl,
) # el parámetro de ajuste, ajusta el ancho de banda de la densidad
#Logit
ctrl<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
number = 10, #mejor 10. no sirve para dato espaciales
classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
verbose=FALSE,
savePredictions = T) #que guarde las predicciones
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.856, 0.01), # iremos variando los valores
lambda = seq(0, 0.0005, 0.0001)) # iremos variando los valores
colnames(hyperparameter_grid) <- c("alpha", "lambda")
set.seed(2023)
nb1 <- train(pobre ~ cuartos_dorm+ nper +Porcentaje_ocupados + v.cabecera
+ Jefe_mujer+ Tipodevivienda +edad
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo ,
data = train,
method = "nb",
trControl = ctrl,
) # el parámetro de ajuste, ajusta el ancho de banda de la densidad
glimpse(train)
table(train$seg_soc)
nb1 <- train(pobre ~ cuartos_dorm+ nper +Porcentaje_ocupados + v.cabecera
+ Jefe_mujer+ Tipodevivienda +edad
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
) # el parámetro de ajuste, ajusta el ancho de banda de la densidad
nb1 <- train(pobre ~ cuartos_dorm+ nper +Porcentaje_ocupados + v.cabecera
+ Jefe_mujer+ Tipodevivienda +edad
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~ v.cabecera
+ Jefe_mujer+ Tipodevivienda
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
+ Jefe_mujer+ Tipodevivienda
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
+ Tipodevivienda
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
+ Tipodevivienda
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
+ seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
seg_soc+ Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
Nivel_educativo+ otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + v.cabecera,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + Jefe_mujer,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + Tipodevivienda,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + Nivel_educativo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm +nper,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm +nper
+Porcentaje_ocupados,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm +nper
+Porcentaje_ocupados +edad,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm +nper
+Porcentaje_ocupados +edad + sexo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.5,0.8), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=1))
nb1
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm +nper
+Porcentaje_ocupados +edad + sexo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0.2,0.25,0.3,0.35), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=seq(0.5,0.8,1)))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm +nper
+Porcentaje_ocupados +edad + sexo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0,1,0.1), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=seq(0,1,0.1)))
nb1 <- train(pobre ~
otro_trab +ocupado + Tipo_de_trabajo + seg_soc + cuartos_dorm +nper
+Porcentaje_ocupados +edad + sexo,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0,0.5,0.1), #fl es la correción de laplace, trata de satisface el problema, warning de las probabilidades=0 (ajusta probabilidades)
usekernel=TRUE, #otro parámetro
adjust=seq(0.5,1,0.1)))
#Logit
ctrl<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
number = 10, #mejor 10. no sirve para dato espaciales
classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
verbose=FALSE,
savePredictions = T) #que guarde las predicciones
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.856, 0.01), # iremos variando los valores
lambda = seq(0, 0.0005, 0.0001)) # iremos variando los valores
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.856, 0.001), # iremos variando los valores
lambda = seq(0, 0.0005, 0.0001)) # iremos variando los valores
#creo iteracciones
#creando interacciones
train$int1<- interaction(train$v.cabecera,train$Jefe_mujer)
train$int2<- interaction(train$d_arriendo,train$Jefe_mujer)
train$int3<- interaction(train$Tipodevivienda, train$Jefe_mujer)
train$int4<- interaction(train$edad, train$Jefe_mujer)
train$int5<- interaction(train$Nivel_educativo, train$Jefe_mujer)
train$int6<- interaction(train$otro_trab, train$Jefe_mujer)
train$int7<- interaction(train$fondo_pensiones, train$Jefe_mujer)
train$int8<- interaction(train$ocupado, train$Jefe_mujer)
#LOGIT4
set.seed(2023)
down_train <- downSample(x = train[, -ncol(train)], #hacemos esto para balancear las muestras
y = train$pobre)
set.seed(2023)
logit4 <- train(pobre~Porcentaje_ocupados+ + v.cabecera +cuartos_hog + nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo
+otro_trab + fondo_pensiones +ocupado + int1 + int2 +int3 +int4
+int5 +int6+ int7,
data = down_train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl2,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
logit4 <- train(pobre~Porcentaje_ocupados+ + v.cabecera +cuartos_hog + nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo
+otro_trab + fondo_pensiones +ocupado + int1 + int2 +int3 +int4
+int5 +int6+ int7,
data = down_train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit4
plot(logit4$results$lambda,
logit4$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit4$bestTune
predictTest_logit4 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit4, type = "prob"),         ## predicted class probabilities
pred = predict(logit4, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
predictTest_logit4 <- data.frame(
obs = down_train$pobre,                    ## observed class labels
predict(logit4, type = "prob"),         ## predicted class probabilities
pred = predict(logit4, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit4)
confusionMatrix(data = predictTest_logit4$pred, reference=predictTest_logit4$obs)
predictTest_logit4 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit4, newdata=train, type = "prob"),         ## predicted class probabilities
pred = predict(logit4, newdata=train, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit4)
confusionMatrix(data = predictTest_logit4$pred, reference=predictTest_logit4$obs)
up_train <- upSample(x = train[, -ncol(train)], #hacemos esto para balancear las muestras
y = train$pobre)
set.seed(2023)
set.seed(2023)
up_train <- upSample(x = train[, -ncol(train)], #hacemos esto para balancear las muestras
y = train$pobre)
set.seed(2023)
logit4 <- train(pobre~Porcentaje_ocupados+ + v.cabecera +cuartos_hog + nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo
+otro_trab + fondo_pensiones +ocupado + int1 + int2 +int3 +int4
+int5 +int6+ int7,
data = up_train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit4
plot(logit4$results$lambda,
logit4$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit4$bestTune
predictTest_logit4 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit4, newdata=train, type = "prob"),         ## predicted class probabilities
pred = predict(logit4, newdata=train, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit4)
confusionMatrix(data = predictTest_logit4$pred, reference=predictTest_logit4$obs)
#Evaluando los cortes/thresholds
roc_data <- roc(predictTest_logit4$obs, predictTest_logit4$Si)
plot(roc_data, main = "ROC Curve", col = "purple", lwd = 2) #vemos nuestra curva ROC. Estamos muy alto en sensitivity y bajo en specificity
mycoords <- coords(roc_data, "all")
plot(mycoords$threshold, mycoords$sensitivity, type = "l", col = "red",
xlab = "Cutoff", ylab = "Sensitivity", main = "Sensitivity vs. Cutoff")
lines(mycoords$threshold, mycoords$specificity, col = "blue")
legend("bottomright", legend = c("Sensitivity", "Specificity"), col = c("red", "blue"), lwd = 2)
#Nueva matiz
predicted_probabilities <- predictTest_logit4$Si
new_cutoff<-0.55
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.60
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
#Nueva matiz
predicted_probabilities <- predictTest_logit4$Si
new_cutoff<-0.60
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.70
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.80
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.85
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.90
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.80
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.82
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.85
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.83
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.81
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.8
new_cutoff<-0.82
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
set.seed(2023)
logit4 <- train(pobre~Porcentaje_ocupados+ + v.cabecera +cuartos_hog + nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo
+otro_trab + fondo_pensiones +ocupado + int1 + int2 +int3 +int4
+int5 +int6+ int7,
data = down_train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit4
plot(logit4$results$lambda,
logit4$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit4$bestTune
logit4
predictTest_logit4 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit4, newdata=train, type = "prob"),         ## predicted class probabilities
pred = predict(logit4, newdata=train, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit4)
confusionMatrix(data = predictTest_logit4$pred, reference=predictTest_logit4$obs)
#Nueva matiz
predicted_probabilities <- predictTest_logit4$Si
new_cutoff<-0.85
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.82
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.75
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.80
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.82
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.83
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
new_cutoff<-0.82
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
set.seed(2023)
logit4 <- train(pobre~Porcentaje_ocupados+ + v.cabecera +cuartos_hog + nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo
+otro_trab + fondo_pensiones +ocupado + int1 + int2 +int3 +int4
+int5 +int6+ int7,
data = up_train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit4
plot(logit4$results$lambda,
logit4$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit4$bestTune
predictTest_logit4 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit4, newdata=train, type = "prob"),         ## predicted class probabilities
pred = predict(logit4, newdata=train, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit4)
confusionMatrix(data = predictTest_logit4$pred, reference=predictTest_logit4$obs)
#Nueva matiz
predicted_probabilities <- predictTest_logit4$Si
new_cutoff<-0.82
predictTest_logit4$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit4$new_thres, reference=predictTest_logit4$obs)
#Logit4: Exporto la predicción en csv para cargarla en Kaggle con corte 0.82
test$pobre <- predict(logit4, newdata = test, type="prob") #adaptamos
#interacciones para test
test$int1<- interaction(test$v.cabecera,test$Jefe_mujer)
test$int2<- interaction(test$d_arriendo,test$Jefe_mujer)
test$int3<- interaction(test$Tipodevivienda, test$Jefe_mujer)
test$int4<- interaction(test$edad, test$Jefe_mujer)
test$int5<- interaction(test$Nivel_educativo, test$Jefe_mujer)
test$int6<- interaction(test$otro_trab, test$Jefe_mujer)
test$int7<- interaction(test$fondo_pensiones, test$Jefe_mujer)
test$int8<- interaction(test$ocupado, test$Jefe_mujer)
#Logit4: Exporto la predicción en csv para cargarla en Kaggle con corte 0.82
test$pobre <- predict(logit4, newdata = test, type="prob") #adaptamos
test$pobre <- test$pobre$Si
test$pobre <- as.factor(ifelse(test$pobre > 0.82, "Si", "No"))
test_logit4 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test_logit4 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
View(test)
test_logit4$pobre <- ifelse(test_logit4$pobre == "No", 0, 1)
View(test)
#Logit4: Exporto la predicción en csv para cargarla en Kaggle con corte 0.82
test$pobre <- predict(logit4, newdata = test, type="prob") #adaptamos
test$pobre <- test$pobre$Si
test$pobre <- as.factor(ifelse(test$pobre > 0.82, "Si", "No"))
test_logit4 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test$pobre <- as.factor(ifelse(test$pobre > 0.82, "Si", "No"))
test_logit4 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
glimpse(test)
#Logit4: Exporto la predicción en csv para cargarla en Kaggle con corte 0.82
test$pobre <- predict(logit4, newdata = test, type="prob") #adaptamos
test$pobre <- test$pobre$Si
#Logit4: Exporto la predicción en csv para cargarla en Kaggle con corte 0.82
test$pobre <- predict(logit4, newdata = test, type="prob") #adaptamos
test$pobre <- test$pobre$Si
test$pobre <- as.factor(ifelse(test$pobre > 0.82, "Si", "No"))
test_logit4 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
glimpse(train)
test_logit4 <- test %>%
select(id, pobre)
glimpse(test)
test_logit4 <- test %>%
select(1, 56)

summary(cars)
summary(cars)
summary(cars)
summary(cars)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
#-skim package-------------------
#Before running the linear model, we check whether all the variables classes are
#either numerical or categorical. A helpful function is skim() from the skimr
#package. This is an alternative to the summary() function in base R, which
#quickly provides a broad overview of a data frame. It handles data of all types,
#dispatching a different set of summary functions based on the types of columns
#in the data frame:
skim(dat)
# Model estimation
mod <- lm(y ~ ., data = dat, x = TRUE)
view(mod)
modglm <- glm(y ~ ., data = dat)
# ver outputs
stargazer(mod,modglm, type="text")
summary(mod)
summ(mod)
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
stat_smooth(formula = 'y ~ x', method = lm, se = FALSE,
size = 1) +  #fit the linear model in the plot
theme_bw() + #black and white theme
labs(x = "Temperature in Celsius",
y = "Number of bicycles rented",
title = "Predicted values with changes in temperature") # labels
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
stat_smooth(formula = 'y ~ x', method = lm, se = FALSE,
size = 1) +  #fit the linear model in the plot
theme_bw() + #black and white theme
labs(x = "Temperature in Celsius",
y = "Number of bicycles rented",
title = "Predicted values with changes in temperature") # labels
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
stat_smooth(formula = 'y ~ x', method = lm, se = FALSE,
size = 1) +  #fit the linear model in the plot
theme_bw() + #black and white theme
labs(x = "Temperature in Celsius",
y = "Number of bicycles rented",
title = "Predicted values with changes in temperature") # labels
# A simple for loop in R
for(i in 1:5) {
print(i)
}
# A simple for loop in R
for(i in 1<5) {
print(i)
}
# A simple for loop in R
for(i in 1>5) {
print(i)
}
#Here
’s a simple example:
# Create a matrix
M <- matrix(c(1:10), nrow = 5)
M
rm(list = ls()) # Limpiar Rstudio
# For syntax
for (value in sequence) {
statements
} # In this syntax, value is the variable that takes on the value of each element in the sequence in turn, and statements are the lines of code executed for each value.
#Here
’s a simple example:
# Create a matrix
M <- matrix(c(1:10), nrow = 5)
M
# Apply the sum function across rows (MARGIN=1)
apply(M, 1, sum)
#Here
’s a simple example:
# Create a list
my_list <- list(a = 1:5, b = 6:10)
my_list
# Apply the sum function to each list element
lapply(my_list, sum)
sessionInfo()
rm(list = ls()) # Limpiar Rstudio
if (!require(pacman)) install.packages("pacman"); require(pacman) # identifica si una librería no está cargada y si es así la empieza a cargar
p_load(ggplot2, rio, tidyverse, skimr, caret) # Cargar varios paquetes al tiempo
library(rvest)
page_1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html")
summary(page_1)
page_1
page_1|> html_elements("p")
page_1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html")
page_1|> html_elements("p")
page_1
page_1|> html_elements("Navugation")
page_1|> html_elements()
# Extraer los párrafos
tablas <- html_sample1 %>%
html_table()
rm(list = ls()) # Limpiar Rstudio
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
sample1 <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
browseURL(sample1) # Abrir el URL de la página
html_sample1 <- read_html(sample1) # cargar el html de la página
html_sample1 # ver el html de la página
# Extraer diferentes elementos de la página
# Extraer los títulos
html_sample1 %>%
html_elements("h3") %>%
html_text()
# Extraer los párrafos
html_sample1 %>%
html_elements("p") %>%
html_text()
# Extraer los párrafos
tablas <- html_sample1 %>%
html_table()
tablas
# Extraer tablas ya creadas
tablas <- html_sample1 %>%
html_table() # en los paréntesis selecciono la tabla que quiero
tablas
# Extraer tablas que se deben formar
tabla <- html_sample1 %>%
html_nodes(xpath = "/html/body/div/div/div[2]/div/table")
tabla
# Extraer tablas que se deben formar
tabla <- html_sample1 %>%
html_nodes(xpath = "/html/body/div/div/div[2]/div/table") %>%
html_table()
sample1 %>%
html_table()
html_sample1 %>%
html_table()
table1 <- read_html("https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css")
table1
view(table1)
as.data.frame(table1)
tabla1 %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
tabla1 <- read_html("https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
tabla1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html") %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
texto <- html_text(nodos)
tabla1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html") %>%
html_table()
tabla1
view(tabla1)
rm(list = ls()) # Limpiar Rstudio
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
rm(list = ls()) # Limpiar Rstudio
options(scipen = 20,  digits=1)
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
rm(list = ls()) # Limpiar Rstudio
options(scipen = 20,  digits=1)
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
table1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html") %>%
html_table()
head(tabla1)
head(table1)
title(table1)
names(table1)
as.data.frame(table1)
names(table1)
?for
for (variable in vector) {
?for
d
for?
data_base <- ("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_") %>%
for (i in 1:10) {
datai <- paste0(data_base, i, ".html")
}
data_base <- ("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_")
head(data_base)
for (i in 1:10) {
datai <- paste0(data_base, i, ".html")
}
# creo un loop para descargar las 10 bases de datos
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
numero_inicial <- 1
numero_final <- 10
for (i in numero_inicial:numero_final) {
url <- paste0(url_base, i, ".html")
pagina <- read_html(url)
}
head(i)
view(i)
paginai <- read_html(url) %>%
html_table()
# creo un loop para descargar las 10 bases de datos
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
paginai <- read_html(url)
html_table()
}
paginai <- read_html(url)
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
paginai <- read_html(url)
}
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
read_html(url)
}
head(url)
citation()
citation("rvest")
citation("car ")
citation("car")
install.packages(c("cpp11", "dbplyr", "digest", "future", "gargle", "haven", "jsonlite", "lme4", "pkgload", "pROC", "processx", "Rcpp", "readxl", "rmarkdown", "rstudioapi", "shiny", "testthat", "vctrs", "webshot", "xml2"))
q()
# Classification ##########################################################
rm(list = ls())
pacman::p_load(tydiverse)
getwd()
pacman::p_load(tydiverse)
pacman::p_load(tidyverse)
getwd()
getwd()
getwd()
getwd()
rm(list = ls()) # Limpiar Rstudio
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
glimpse(train) # visualizamos los datos
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
table(train$pobre) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
33024/164960
# Creo control por valicación cruzada
cv<-trainControl(method="cv",
number=5,
classProbs=TRUE, #retorna la probabilidad de cada una de las clases
verbose=TRUE, #
savePredictions=T) #que guarde las predicciones
glimpse(train)
train_1 <- train %>%
select(-pobre)
test_1 <- test %>%
select(-pobre)
mod_rf_1 <- train(
IngresoPerCapita ~ .,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
test_1 <- test %>%
select(-pobre)
#omito variable de interés binaria para la estimación
train_1 <- train %>%
select(-pobre)
# selecciono variables de mayor interés
train_1 <- select(train)
names(train)
# selecciono variables de mayor interés
train_1 <- select(train, c(1:9, 13:23, 25:48))
test_1 <- select(test, c(1:9, 13:23, 25:48))
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
mod_rf_1 <- train(
pobre ~ . - id - IngresoPerCapita,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
names(train_1)
mod_rf_1 <- train(
pobre ~ . - id - IngresoPerCapita,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
glimpse(train) # visualizamos los datos
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
table(train$pobre) #los datos estan desbalanceados
table.pro(table(train$pobre)) #los datos estan desbalanceados
table.per(table(train$pobre)) #los datos estan desbalanceados
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
prop.table(table(train$pobre)) #los datos estan desbalanceados
# selecciono variables de mayor interés
train_1 <- select(train, c(1:9, 13:23, 25:48))
test_1 <- select(test, c(1:9, 13:23, 25:48))
# Creo control por valicación cruzadamod_fr_1$bestTune
cv<-trainControl(method="cv",
number=5,
classProbs=TRUE, #retorna la probabilidad de cada una de las clases
verbose=TRUE, #
savePredictions=T) #que guarde las predicciones
names(train)
# selecciono variables de mayor interés
train <- select(train, c(1:9, 13:23, 25:48))
test <- select(test, c(1:9, 13:23, 25:48))
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
rm(list = ls()) # Limpiar Rstudio
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
# selecciono variables de mayor interés
train <- select(train, c(1:9, 13:23, 25:48))
test <- select(test, c(1:9, 13:23, 25:48))
glimpse(train) # visualizamos los datos
names(train)
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
train<-readRDS("../stores/train_final.rds")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test_1_1<-readRDS("../stores/test_1_final.rds")
#Importamos las bases
test<-readRDS("../stores/test_1_final.rds")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
# selecciono variables de mayor interés
train <- select(train, c(1:6, 8, 9, 13:24, 25:44, 47, 48))
test <- select(test, c(1:6, 8, 9, 13:24, 25:44, 47, 48))
names(train)
glimpse(train)
summary(train)
table(cuartos$hogar)
table(train$cuartos_hog)
table(train$cuartos_dorm)
table(train$Jefe_hogar)
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")

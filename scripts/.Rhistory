mylogit_nb <- train(Default~duration+amount+installment+age+
history.buena+history.mala+
purpose.auto_nuevo+purpose.auto_usado+purpose.bienes+purpose.educacion+
foreign.extranjero+
+rent.TRUE,
data = train,
method = "nb",
trControl = ctrl,
tuneGrid=expand.grid(fL=seq(0,10,length.out = 3),
usekernel=TRUE,
adjust=seq(1,10,length.out = 3)))
#Cargar librerías
require("pacman")
p_load(tidyverse)
set.seed(1011)
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
head(credit)
#mutación de factores- queremos crear dummies
credit<-credit %>% mutate(Default=factor(Default,levels=c(0,1),labels=c("No","Si")),
history=factor(history,levels=c("good","poor","terrible"),labels=c("buena","mala","terrible")),
foreign=factor(foreign,levels=c("foreign","german"),labels=c("extranjero","aleman")),
purpose=factor(purpose,levels=c("newcar","usedcar","goods/repair","edu", "biz" ),labels=c("auto_nuevo","auto_usado","bienes","educacion","negocios")))
p_load("caret")
inTrain <- createDataPartition(
y = credit$Default,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
train <- credit[ inTrain,]
test  <- credit[-inTrain,]
ctrl<- trainControl(method = "cv",
number = 5,
classProbs = TRUE,
verbose=FALSE,
savePredictions = T)
set.seed(123)
#si default es un factor, entonces rpart se da cuenta que es un problema de clasificacion
#sino, bota un warning y lo trata como regreison
class_arboles <- train(Default~duration+amount+installment+age+history + purpose+foreign+rent,
data = train,
method = "rpart", #arboles
trControl = ctrl,
tuneLength=100) #100 alphas
class_arboles
#mutación de factores- queremos crear dummies
credit<-credit %>% mutate(Default=factor(Default,levels=c(0,1),labels=c("No","Si")),
history=factor(history,levels=c("good","poor","terrible"),labels=c("buena","mala","terrible")),
foreign=factor(foreign,levels=c("foreign","german"),labels=c("extranjero","aleman")),
purpose=factor(purpose,levels=c("newcar","usedcar","goods/repair","edu", "biz" ),labels=c("auto_nuevo","auto_usado","bienes","educacion","negocios")))
p_load("caret")
inTrain <- createDataPartition(
y = credit$Default,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
train <- credit[ inTrain,]
test  <- credit[-inTrain,]
#Cargar librerías
require("pacman")
p_load(tidyverse)
set.seed(1011)
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
head(credit)
#mutación de factores- queremos crear dummies
credit<-credit %>% mutate(Default=factor(Default,levels=c(0,1),labels=c("No","Si")),
history=factor(history,levels=c("good","poor","terrible"),labels=c("buena","mala","terrible")),
foreign=factor(foreign,levels=c("foreign","german"),labels=c("extranjero","aleman")),
purpose=factor(purpose,levels=c("newcar","usedcar","goods/repair","edu", "biz" ),labels=c("auto_nuevo","auto_usado","bienes","educacion","negocios")))
p_load("caret")
inTrain <- createDataPartition(
y = credit$Default,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
train <- credit[ inTrain,]
test  <- credit[-inTrain,]
ctrl<- trainControl(method = "cv",
number = 5,
classProbs = TRUE,
verbose=FALSE,
savePredictions = T)
set.seed(123)
#si default es un factor, entonces rpart se da cuenta que es un problema de clasificacion
#sino, bota un warning y lo trata como regreison
class_arboles <- train(Default~duration+amount+installment+age+history + purpose+foreign+rent,
data = train,
method = "rpart", #arboles
trControl = ctrl,
tuneLength=100) #100 alphas
class_arboles
predictTest_arbol <- data.frame(
obs = test$Default,                                    ## observed class labels
predict(class_arboles, newdata = test, type = "prob"),         ## predicted class probabilities
pred = predict(class_arboles, newdata = test, type = "raw")    ## predicted class labels
)
head(predictTest_arbol)
# Accuracy
mean(predictTest_arbol$obs==predictTest_arbol$pred)
p_load("rpart.plot")
prp(class_arboles$finalModel, under = TRUE, branch.lty = 2, yesno = 2, faclen = 0, varlen=15,tweak=1.2,clip.facs= TRUE,box.palette = "Greens",compress=FALSE,ycompress = FALSE)
#Bosques
set.seed(123)
class_bosques <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "ranger",
trControl = ctrl,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(15,30,45,60))
)
class_bosques <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "ranger",
trControl = ctrl,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8), #cualquier subconjunto es bagging
splitrule = "gini", #parta el arbol a traves de gini
min.node.size = c(15,30,45,60)) #controlamos la profundidad del arbol por el numero de obs minimo
)
class_bosques
predictTest_bosque <- data.frame(
obs = test$Default,                                    ## observed class labels
predict(class_bosques, newdata = test, type = "prob"),         ## predicted class probabilities
pred = predict(class_bosques, newdata = test, type = "raw")    ## predicted class labels
)
# Accuracy
mean(predictTest_bosque$obs==[predictTest_bosque$pred)
# Accuracy
mean(predictTest_bosque$obs==predictTest_bosque$pred)
#AdaBoost
p_load("adabag")
set.seed(123)
class_adaboost <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "AdaBoost.M1",
trControl = ctrl,
tuneGrid=expand.grid(
mfinal = c(50,100,150),
maxdepth = c(1,2,3),
coeflearn = c('Breiman','Freund'))
)
class_adaboost
class_adaboost <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "AdaBoost.M1",
trControl = ctrl,
tuneGrid=expand.grid(
mfinal = c(50,100,150),
maxdepth = c(1,2,3),
coeflearn = c('Breiman','Freund'))
)
#Cargar librerías
require("pacman")
p_load("tidyverse")
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
#Cargar librerías
require("pacman")
p_load("tidyverse")
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
#mutacion de factores
credit<-credit %>% mutate(Default=factor(Default,levels=c(1,0),labels=c("Si","No")),
history=factor(history,levels=c("good","poor","terrible"),labels=c("buena","mala","terrible")),
foreign=factor(foreign,levels=c("foreign","german"),labels=c("extranjero","aleman")),
purpose=factor(purpose,levels=c("newcar","usedcar","goods/repair","edu", "biz" ),labels=c("auto_nuevo","auto_usado","bienes","educacion","negocios")))
head(credit)
prop.table(table(credit$Default))
## First, split the training set
set.seed(1011)
p_load("caret")
inTrain <- createDataPartition(
y = credit$Default,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
train <- credit[ inTrain,]
test  <- credit[-inTrain,]
ctrl<- trainControl(method = "cv", #cross validation
number = 5, #number of folds
classProbs = TRUE, #retorne la probabilidad de clases
savePredictions = T) #retorne predicciones
set.seed(123)
class_ranger <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "Accuracy", #especificamos que queremos que maximice accuracy
method = "ranger", #bosque
trControl = ctrl,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8), #numero de prodectores
splitrule = "gini", #usando la regla que divide arboles con gini
min.node.size = c(25,50,150,200,250)) #profundidad, número de observaciones en cada nodo (lo mínimo que tienen que tener). mientras más observaciones, menos profundo será el árbol
)
class_ranger
#ahora usamos el F^train (de validacoón cruzada) reemplazamos en los observados de la muestra de entrenamiento (xtrain)= retorna una probabilidad
#usamos la clasificación de bayes 1[p^>0.5]
predictSample <- train   %>%
mutate(hat_default = predict(class_ranger, newdata = train, type = "raw")    ## predicted class labels. type raw= clasificador de bayes. esto dentro de train
)  %>% select(Default,hat_default) #nos quedamos solo con el observado y predicho
head(predictSample)
#miramos resultados
confusionMatrix(data = predictSample$hat_default, reference=predictSample$Default)
# Accuracy (A MANO)
mean(predictSample$Default==predictSample$ hat_default)
#quiero predecir bien fuera de muestra
predictTest <- data.frame(
Default = test$Default,                                    ## observed class labels
hat_default = predict(class_ranger, newdata = test, type = "raw")    ## predicted class labels
)
confusionMatrix(data = predictTest$hat_default, reference=predictTest$Default)
ctrl2<- trainControl(method = "cv",
number = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE,
savePredictions = T)
set.seed(123)
class_ranger_sens <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "Sens", #antes poníamos accuracy, ahora cambiamos a sens
method = "ranger",
trControl = ctrl2,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(25,50,150,200,250))
)
class_ranger_sens
#pero yo lo quiero fuera de muestra
predictTest<- test   %>%
mutate(hat_default_sens = predict(class_ranger_sens, newdata = test, type = "raw")    ## predicted class labels
)  %>% select(Default,hat_default_sens)
confusionMatrix(data = predictTest$hat_default,reference=predictTest$Default)
class_ranger_ROC <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "ROC", #area bajo la curva
method = "ranger",
trControl = ctrl2,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(25,50,150,200,250))
)
class_ranger_ROC
#phat ROC= prob hat(y=si|x)
predictTest <- predictTest  %>%
mutate(class_ROC = predict(class_ranger_ROC, newdata = test, type = "raw"), # predicted class labels
p_hat_ROC=predict(class_ranger_ROC, newdata = test, type = "prob")$Si,         ## predicted class probabilities#
Default_num=ifelse(Default=="No",0,1) #si default es no, reemplazamos por 0, sino, 1
)
head(predictTest)
confusionMatrix(data = predictTest$class_ROC, reference=predictTest$Default)
p_load("pROC")
rfROC <- roc(predictTest$Default, predictTest$p_hat_ROC, levels = rev(levels(predictTest$Default)))
rfROC
FPR<-mean(predictTest$class_ROC[predictTest$Default=="No"]=="No")
TPR<-mean(predictTest$class_ROC[predictTest$Default=="Si"]=="Si")
plot(rfROC)
FPR<-mean(predictTest$class_ROC[predictTest$Default=="No"]=="No")
TPR<-mean(predictTest$class_ROC[predictTest$Default=="Si"]=="Si")
plot(rfROC)
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
predictTest <- predictTest  %>%
mutate(class_ROC_2 = factor(ifelse(p_hat_ROC>.2,"Si","No"),levels=c("Si","No"))
)
confusionMatrix(data = predictTest$class_ROC_2, reference=predictTest$Default)
FPR_2<-mean(predictTest$class_ROC_2[predictTest$Default=="No"]=="No")
TPR_2<-mean(predictTest$class_ROC_2[predictTest$Default=="Si"]=="Si")
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
## our .5 rule cutoff
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
## A .2 rule cutoff
points(x= FPR_2,
y=TPR_2,
cex=4, pch=20, col='blue')
#Closest to top left cutoff
rfThresh <- coords(rfROC, x = "best", best.method = "closest.topleft")
rfThresh
predictTest <- predictTest  %>%
mutate(class_ROC_Thresh = factor(ifelse(p_hat_ROC>rfThresh$threshold,"Si","No"),levels=c("Si","No")) #en base al resultado anterior, pongo el threshold.
)
confusionMatrix(data = predictTest$class_ROC_Thresh, reference=predictTest$Default)
FPR_3<-mean(predictTest$class_ROC_Thresh[predictTest$Default=="No"]=="No")
TPR_3<-mean(predictTest$class_ROC_Thresh[predictTest$Default=="Si"]=="Si")
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
## our .5 rule cutoff
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
## A optimal threshold
points(x= FPR_3,
y=TPR_3,
cex=4, pch=20, col='green')
setwd("users/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("user/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("Users/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("User/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret, dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
#vemos que hay en el directorio de stores
dir("../stores")
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#vemos variables
names(train)
#renombramos variable Pobre a pobre
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
table(train$pobre) #los datos estan desbalanceados
glimpse(train)
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"), labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"), labels = c("No", "Si"))
#Correlation matrix
numeric_train <- train %>% select_if(is.numeric) #separamos las numericas
numeric_train <- ungroup(numeric_train) %>% select(-id)
cor_matrix <- cor(numeric_train) #calculamos correlacion
# Print the correlation matrix
print(cor_matrix)
corrplot(cor_matrix, method = "color")
pacman::p_load(ggplot2, tidyverse, caret, dplyr, tidyr, glmnet, pROC, corrplot) # Cargar paquetes requeridos
# Print the correlation matrix
print(cor_matrix)
# Print the correlation matrix
pairs(numeric_train)
# Print the correlation matrix
pairs(numeric_train)
print(cor_matrix)
# LDA -------------------------------------
lda_1 = train(pobre~cuartos_hog+ cuartos_dorm + nper+Li #saco npersug porque tiene muy alta correlacion con nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo,
data=train,
method="lda",
trControl = ctrl,
metric="Accuracy")
#Logit
ctrl<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
number = 10, #mejor 10. no sirve para dato espaciales
classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
verbose=FALSE,
savePredictions = T) #que guarde las predicciones
setseed(1234)
set.seed(1234)
lda_1 = train(pobre~cuartos_hog+ cuartos_dorm + nper+Li #saco npersug porque tiene muy alta correlacion con nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo,
data=train,
method="lda",
trControl = ctrl,
metric="Accuracy")
warnings()
lda_1 = train(pobre~cuartos_hog+ nper+Li #saco npersug porque tiene muy alta correlacion con nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo,
data=train,
method="lda",
trControl = ctrl,
metric="Accuracy")
warnings()
selected_vars <- train %>%
select(cuartos_hog, nper, Li, d_arriendo, Jefe_mujer, PersonaxCuarto,
Tipodevivienda, Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
otro_trab, ocupado, desocupado, inactivo)
cor_matrix2 <- cor(selected_vars)
train_ungrouped <- train %>% ungroup()
# Select the relevant columns
selected_vars <- train_ungrouped %>%
select(cuartos_hog, nper, Li, d_arriendo, Jefe_mujer, PersonaxCuarto,
Tipodevivienda, Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
otro_trab, ocupado, desocupado, inactivo)
# Convert categorical variables into dummy variables using one-hot encoding
selected_vars <- selected_vars %>%
dummyVars() %>%
predict(selected_vars)
train_ungrouped <- train %>% ungroup()
selected_vars <- train_ungrouped %>%
select(cuartos_hog, nper, Li, d_arriendo, Jefe_mujer, PersonaxCuarto,
Tipodevivienda, Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
otro_trab, ocupado, desocupado, inactivo)
selected_vars <- selected_vars %>%
dummyVars() %>%
predict(selected_vars)
dummy_vars <- dummyVars(~., data = selected_vars)
selected_vars <- predict(dummy_vars, newdata = selected_vars)
cor_matrix2 <- cor(selected_vars)
print(cor_matrix2)
lda_1 = train(pobre~cuartos_hog+ nper+Li #saco npersug y cuartos hogar porque tiene muy alta correlacion con nper
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo,
data=train,
method="lda",
trControl = ctrl,
metric="Accuracy")
lda_1 = train(pobre~cuartos_hog+ nper+Li #saco npersug y cuartos hogar porque tiene muy alta correlacion con nper
+ Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo,
data=train,
method="lda",
trControl = ctrl,
metric="Accuracy")
warning()
lda_1 = train(pobre~cuartos_hog+ nper+Li #saco npersug y cuartos hogar porque tiene muy alta correlacion con nper
+ Jefe_mujer+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo,
data=train,
method="lda",
trControl = ctrl,
metric="Accuracy")
lda_1 = train(pobre~cuartos_hog+ nper+Li #saco npersug y cuartos hogar porque tiene muy alta correlacion con nper
+ Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado,
data=train,
method="lda",
trControl = ctrl,
metric="Accuracy")
lda_1
# Exporto la predicción en csv para cargar en Kaggle
test$pobre <- predict(lda_1, newdata = test) #adaptamos
test_lda <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test_lda$pobre <- ifelse(test_lda$pobre == "No", 0, 1)
head(test_lda) #evalúo que la base esté correctamente creada
write.csv(test_lda,"../stores/lda1.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle
#Logit
ctrl<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
number = 10, #mejor 10. no sirve para dato espaciales
classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
verbose=FALSE,
savePredictions = T) #que guarde las predicciones
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.85, 0.87, 0.01), # iremos variando los valores
lambda = seq(0, 0.1, 0.01)) # iremos variando los valores
colnames(hyperparameter_grid) <- c("alpha", "lambda")
logit1 <- train(pobre~cuartos_hog+ cuartos_dorm + nper+ npersug+Li
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit1
plot(logit1$results$lambda,
logit1$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
#Adaptamos hiperparámetros en base a esto
logit1$bestTune
set.seed(2023)
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.85, 0.87, 0.01), # iremos variando los valores
lambda = seq(0, 0.1, 0.01)) # iremos variando los valores
colnames(hyperparameter_grid) <- c("alpha", "lambda")
logit1 <- train(pobre~cuartos_hog+ cuartos_dorm + nper+ npersug+Li
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit1
plot(logit1$results$lambda,
logit1$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
#Adaptamos hiperparámetros en base a esto
logit1$bestTune
predictTest_logit <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit1, type = "prob"),         ## predicted class probabilities
pred = predict(logit1, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit)
confusionMatrix(data = predictTest_logit$hat_default, reference=predictTest_logit$Default)

q()
Load Packages
#Load Packages
require("pacman")
p_load("tidyverse","stargazer")
options(device = "cairo")  # o "quartz"
p_load("tidyverse","stargazer")
p_load("tidyverse","stargazer")
nlsy = read_csv('https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/nlsy97.csv')
nlsy = nlsy  %>%   drop_na(educ) #dropea los
spec()
spec(nlsy)
`spec()`
spec()
spec(FALSE)
spec(TRUE)
nlsy = read_csv('https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/nlsy97.csv')
nlsy = nlsy  %>%   drop_na(educ) #dropea los valores faltantes (NA)
View(nlsy)
View(nlsy$educ)
head(nlsy$educ)
sum(nlsy$educ)
summarise(nlsy$educ)
hist(nlsy$educ)
summary(nlsy$educ)
require(pacman)
p_load(tidyverse,fixest, stargazer,knitr,kableExtra,jtools,ggstance,broom,broom.mixed,skimr)
# Ejemplo: Predicting bike rentals with linear regression
ls
# Ejemplo: Predicting bike rentals with linear regression
# Clean environment
rm(list = ls())
# Load relevant packages
require(pacman)
p_load(tidyverse,fixest, stargazer,knitr,kableExtra,jtools,ggstance,broom,broom.mixed,skimr)
# Import dataset
load(url("https://github.com/ignaciomsarmiento/datasets/blob/main/bike.RData?raw=true"))
str(bike)
glimpse(bike)
summary(cnt)
summary(bike$cnt)
install.packages(c("broom", "bslib", "gargle", "googledrive", "googlesheets4"))
#select variables used in he analysis
bike.features.of.interest = c('season','holiday', 'workingday', 'weathersit', 'temp', 'hum', 'windspeed', 'days_since_2011')
X <- bike %>% select(bike.features.of.interest)
#select variables used in he analysis
library(magrittr)
bike.features.of.interest = c('season','holiday', 'workingday', 'weathersit', 'temp', 'hum', 'windspeed', 'days_since_2011')
X <- bike %>% select(bike.features.of.interest)
rm(list = ls())
# Load relevant packages
require(pacman)
p_load(tidyverse,fixest, stargazer,knitr,kableExtra,jtools,ggstance,broom,broom.mixed,skimr)
# Import dataset
load(url("https://github.com/ignaciomsarmiento/datasets/blob/main/bike.RData?raw=true"))
bike.features.of.interest = c('season','holiday', 'workingday', 'weathersit', 'temp', 'hum', 'windspeed', 'days_since_2011')
X <- bike %>% select(bike.features.of.interest)
#select dependent variable used in he analysis
y <- bike %>%
select(cnt)  %>%
rename(y=cnt)
# Unir variables vectores X y Y
dat = cbind(X, y)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
summary(cars)
summary(cars)
summary(cars)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
#-skim package-------------------
#Before running the linear model, we check whether all the variables classes are
#either numerical or categorical. A helpful function is skim() from the skimr
#package. This is an alternative to the summary() function in base R, which
#quickly provides a broad overview of a data frame. It handles data of all types,
#dispatching a different set of summary functions based on the types of columns
#in the data frame:
skim(dat)
# Model estimation
mod <- lm(y ~ ., data = dat, x = TRUE)
view(mod)
modglm <- glm(y ~ ., data = dat)
# ver outputs
stargazer(mod,modglm, type="text")
summary(mod)
summ(mod)
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
stat_smooth(formula = 'y ~ x', method = lm, se = FALSE,
size = 1) +  #fit the linear model in the plot
theme_bw() + #black and white theme
labs(x = "Temperature in Celsius",
y = "Number of bicycles rented",
title = "Predicted values with changes in temperature") # labels
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
stat_smooth(formula = 'y ~ x', method = lm, se = FALSE,
size = 1) +  #fit the linear model in the plot
theme_bw() + #black and white theme
labs(x = "Temperature in Celsius",
y = "Number of bicycles rented",
title = "Predicted values with changes in temperature") # labels
ggplot(dat, aes(y = y, x = temp)) +
geom_point() + # add points
stat_smooth(formula = 'y ~ x', method = lm, se = FALSE,
size = 1) +  #fit the linear model in the plot
theme_bw() + #black and white theme
labs(x = "Temperature in Celsius",
y = "Number of bicycles rented",
title = "Predicted values with changes in temperature") # labels
# A simple for loop in R
for(i in 1:5) {
print(i)
}
# A simple for loop in R
for(i in 1<5) {
print(i)
}
# A simple for loop in R
for(i in 1>5) {
print(i)
}
#Here
’s a simple example:
# Create a matrix
M <- matrix(c(1:10), nrow = 5)
M
rm(list = ls()) # Limpiar Rstudio
# For syntax
for (value in sequence) {
statements
} # In this syntax, value is the variable that takes on the value of each element in the sequence in turn, and statements are the lines of code executed for each value.
#Here
’s a simple example:
# Create a matrix
M <- matrix(c(1:10), nrow = 5)
M
# Apply the sum function across rows (MARGIN=1)
apply(M, 1, sum)
#Here
’s a simple example:
# Create a list
my_list <- list(a = 1:5, b = 6:10)
my_list
# Apply the sum function to each list element
lapply(my_list, sum)
sessionInfo()
rm(list = ls()) # Limpiar Rstudio
if (!require(pacman)) install.packages("pacman"); require(pacman) # identifica si una librería no está cargada y si es así la empieza a cargar
p_load(ggplot2, rio, tidyverse, skimr, caret) # Cargar varios paquetes al tiempo
library(rvest)
page_1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html")
summary(page_1)
page_1
page_1|> html_elements("p")
page_1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html")
page_1|> html_elements("p")
page_1
page_1|> html_elements("Navugation")
page_1|> html_elements()
# Extraer los párrafos
tablas <- html_sample1 %>%
html_table()
rm(list = ls()) # Limpiar Rstudio
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
sample1 <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
browseURL(sample1) # Abrir el URL de la página
html_sample1 <- read_html(sample1) # cargar el html de la página
html_sample1 # ver el html de la página
# Extraer diferentes elementos de la página
# Extraer los títulos
html_sample1 %>%
html_elements("h3") %>%
html_text()
# Extraer los párrafos
html_sample1 %>%
html_elements("p") %>%
html_text()
# Extraer los párrafos
tablas <- html_sample1 %>%
html_table()
tablas
# Extraer tablas ya creadas
tablas <- html_sample1 %>%
html_table() # en los paréntesis selecciono la tabla que quiero
tablas
# Extraer tablas que se deben formar
tabla <- html_sample1 %>%
html_nodes(xpath = "/html/body/div/div/div[2]/div/table")
tabla
# Extraer tablas que se deben formar
tabla <- html_sample1 %>%
html_nodes(xpath = "/html/body/div/div/div[2]/div/table") %>%
html_table()
sample1 %>%
html_table()
html_sample1 %>%
html_table()
table1 <- read_html("https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css")
table1
view(table1)
as.data.frame(table1)
tabla1 %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
tabla1 <- read_html("https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
tabla1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html") %>%
html_nodes(xpath = "https://ignaciomsarmiento.github.io/assets/css/bootstrap.min.css") %>%
html_table()
texto <- html_text(nodos)
tabla1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html") %>%
html_table()
tabla1
view(tabla1)
rm(list = ls()) # Limpiar Rstudio
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
rm(list = ls()) # Limpiar Rstudio
options(scipen = 20,  digits=1)
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
rm(list = ls()) # Limpiar Rstudio
options(scipen = 20,  digits=1)
require(pacman)
p_load(ggplot2, rio, tidyverse, skimr, caret, rvest, magrittr) # Cargar varios paquetes al tiempo
table1 <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html") %>%
html_table()
head(tabla1)
head(table1)
title(table1)
names(table1)
as.data.frame(table1)
names(table1)
?for
for (variable in vector) {
?for
d
for?
data_base <- ("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_") %>%
for (i in 1:10) {
datai <- paste0(data_base, i, ".html")
}
data_base <- ("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_")
head(data_base)
for (i in 1:10) {
datai <- paste0(data_base, i, ".html")
}
# creo un loop para descargar las 10 bases de datos
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
numero_inicial <- 1
numero_final <- 10
for (i in numero_inicial:numero_final) {
url <- paste0(url_base, i, ".html")
pagina <- read_html(url)
}
head(i)
view(i)
paginai <- read_html(url) %>%
html_table()
# creo un loop para descargar las 10 bases de datos
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
paginai <- read_html(url)
html_table()
}
paginai <- read_html(url)
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
paginai <- read_html(url)
}
for (i in 1:10) {
url <- paste0(url_base, i, ".html")
read_html(url)
}
head(url)
citation()
citation("rvest")
citation("car ")
citation("car")
install.packages(c("cpp11", "dbplyr", "digest", "future", "gargle", "haven", "jsonlite", "lme4", "pkgload", "pROC", "processx", "Rcpp", "readxl", "rmarkdown", "rstudioapi", "shiny", "testthat", "vctrs", "webshot", "xml2"))
q()
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, rio, tidyverse, skimr, caret,
rvest, magrittr, rstudioapi, stargazer,
boot, readxl, knitr, kableExtra,
glmnet, sf, tmaptools, leaflet,
tokenizers, stopwords, SnowballC,
stringi, dplyr, stringr, sp, hunspell,
car) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
i
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
pacman::p_load(ggplot2, rio, tidyverse, skimr, caret,
pacman::p_load(ggplot2, rio, tidyverse, skimr, caret,
rvest, magrittr, rstudioapi, stargazer,
boot, readxl, knitr, kableExtra,
glmnet, sf, tmaptools, leaflet,
tokenizers, stopwords, SnowballC,
stringi, dplyr, stringr, sp, hunspell,
car,
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
rattle) # graficar los árgoles) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, rio, tidyverse, skimr, caret,
rvest, magrittr, rstudioapi, stargazer,
boot, readxl, knitr, kableExtra,
glmnet, sf, tmaptools, leaflet,
tokenizers, stopwords, SnowballC,
stringi, dplyr, stringr, sp, hunspell,
car,
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
rattle) # graficar los árgoles) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
rm(path_folder, path_script)
dir("../../../)
dir("../../../)
dir("../../../")
dir("../../")
dir("../../../Problems Sets")
dir("../../../Problems Sets/Problem set 3)
"../stores/train.csv"
dir("../../../Problems Sets/Problem set 3")
dir("../../../Problems Sets/Problem set 3/train_hogares.csv")
#train data
train_hogar<-read_csv("../../../Problems Sets/Problem set 3/train_hogares.csv")
train_persona<-read_csv("../../../Problems Sets/Problem set 3/train_personas.csv")
test_hogar<-read_csv("../../../Problems Sets/Problem set 3/test_hogares.csv")
test_persona<-read_csv("../../../Problems Sets/Problem set 3/test_personas.csv")
train_hogar<-train_hogar %>% mutate(sample_level="train_hogar")
train_persona<-train_persona %>% mutate(sample_level="train_persona")
test_hogar<-test_hogar %>% mutate(sample_level="test_hogar")
test_persona<-test_persona %>% mutate(sample_level="test_persona")
data_hogar<-rbind(test_hogar,train_hogar) #juntamos ambas bases
data_hogar<-cbind(test_hogar,train_hogar) #juntamos ambas bases
summary(test_hogar, train_hogar)
# guardo las bases en formato r
save(train_hogar, file = "../stores/train_hogar.RData")
a <- load("../stores/train_hogar.RData")
saveRDS(train_hogar, file = "../stores/train_hogar.rds")
a <- load("../stores/train_hogar.rds")
a <- load("../stores/train_hogar.rds")
save(train_hogar, file = "datos.R")
save(train_hogar, file = "../stores/datos.R")
a <- load("../stores/datos.R")
b <- load("../stores/datos.R")
view(b)
# guardo las bases en formato r
saveRDS(train_hogar, file = "../stores/train_hogar.rds")
# guardo las bases en formato r
saveRDS(train_hogar, file = "../stores/train_hogar.rds")
c <- readRDS(train_hogar, file = "../stores/train_hogar.rds")
saveRDS(test_hogar, file = "../stores/test_hogar.rds")
saveRDS(train_persona, file = "../stores/train_persona.rds")
saveRDS(test_persona, file = "../stores/test_persona.rds")
# para importar las bases utilizo readRDS()
train_hogar1 <- readRDS("../stores/train_hogar.rds")
rm(train_hogar1)
names(train_hogar)
names(test_hogar)

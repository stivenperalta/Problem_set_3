predictTest_bosque <- data.frame(
obs = test$Default,                                    ## observed class labels
predict(class_bosques, newdata = test, type = "prob"),         ## predicted class probabilities
pred = predict(class_bosques, newdata = test, type = "raw")    ## predicted class labels
)
# Accuracy
mean(predictTest_bosque$obs==[predictTest_bosque$pred)
# Accuracy
mean(predictTest_bosque$obs==predictTest_bosque$pred)
#AdaBoost
p_load("adabag")
set.seed(123)
class_adaboost <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "AdaBoost.M1",
trControl = ctrl,
tuneGrid=expand.grid(
mfinal = c(50,100,150),
maxdepth = c(1,2,3),
coeflearn = c('Breiman','Freund'))
)
class_adaboost
class_adaboost <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "AdaBoost.M1",
trControl = ctrl,
tuneGrid=expand.grid(
mfinal = c(50,100,150),
maxdepth = c(1,2,3),
coeflearn = c('Breiman','Freund'))
)
#Cargar librerías
require("pacman")
p_load("tidyverse")
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
#Cargar librerías
require("pacman")
p_load("tidyverse")
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
#mutacion de factores
credit<-credit %>% mutate(Default=factor(Default,levels=c(1,0),labels=c("Si","No")),
history=factor(history,levels=c("good","poor","terrible"),labels=c("buena","mala","terrible")),
foreign=factor(foreign,levels=c("foreign","german"),labels=c("extranjero","aleman")),
purpose=factor(purpose,levels=c("newcar","usedcar","goods/repair","edu", "biz" ),labels=c("auto_nuevo","auto_usado","bienes","educacion","negocios")))
head(credit)
prop.table(table(credit$Default))
## First, split the training set
set.seed(1011)
p_load("caret")
inTrain <- createDataPartition(
y = credit$Default,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
train <- credit[ inTrain,]
test  <- credit[-inTrain,]
ctrl<- trainControl(method = "cv", #cross validation
number = 5, #number of folds
classProbs = TRUE, #retorne la probabilidad de clases
savePredictions = T) #retorne predicciones
set.seed(123)
class_ranger <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "Accuracy", #especificamos que queremos que maximice accuracy
method = "ranger", #bosque
trControl = ctrl,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8), #numero de prodectores
splitrule = "gini", #usando la regla que divide arboles con gini
min.node.size = c(25,50,150,200,250)) #profundidad, número de observaciones en cada nodo (lo mínimo que tienen que tener). mientras más observaciones, menos profundo será el árbol
)
class_ranger
#ahora usamos el F^train (de validacoón cruzada) reemplazamos en los observados de la muestra de entrenamiento (xtrain)= retorna una probabilidad
#usamos la clasificación de bayes 1[p^>0.5]
predictSample <- train   %>%
mutate(hat_default = predict(class_ranger, newdata = train, type = "raw")    ## predicted class labels. type raw= clasificador de bayes. esto dentro de train
)  %>% select(Default,hat_default) #nos quedamos solo con el observado y predicho
head(predictSample)
#miramos resultados
confusionMatrix(data = predictSample$hat_default, reference=predictSample$Default)
# Accuracy (A MANO)
mean(predictSample$Default==predictSample$ hat_default)
#quiero predecir bien fuera de muestra
predictTest <- data.frame(
Default = test$Default,                                    ## observed class labels
hat_default = predict(class_ranger, newdata = test, type = "raw")    ## predicted class labels
)
confusionMatrix(data = predictTest$hat_default, reference=predictTest$Default)
ctrl2<- trainControl(method = "cv",
number = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE,
savePredictions = T)
set.seed(123)
class_ranger_sens <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "Sens", #antes poníamos accuracy, ahora cambiamos a sens
method = "ranger",
trControl = ctrl2,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(25,50,150,200,250))
)
class_ranger_sens
#pero yo lo quiero fuera de muestra
predictTest<- test   %>%
mutate(hat_default_sens = predict(class_ranger_sens, newdata = test, type = "raw")    ## predicted class labels
)  %>% select(Default,hat_default_sens)
confusionMatrix(data = predictTest$hat_default,reference=predictTest$Default)
class_ranger_ROC <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "ROC", #area bajo la curva
method = "ranger",
trControl = ctrl2,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(25,50,150,200,250))
)
class_ranger_ROC
#phat ROC= prob hat(y=si|x)
predictTest <- predictTest  %>%
mutate(class_ROC = predict(class_ranger_ROC, newdata = test, type = "raw"), # predicted class labels
p_hat_ROC=predict(class_ranger_ROC, newdata = test, type = "prob")$Si,         ## predicted class probabilities#
Default_num=ifelse(Default=="No",0,1) #si default es no, reemplazamos por 0, sino, 1
)
head(predictTest)
confusionMatrix(data = predictTest$class_ROC, reference=predictTest$Default)
p_load("pROC")
rfROC <- roc(predictTest$Default, predictTest$p_hat_ROC, levels = rev(levels(predictTest$Default)))
rfROC
FPR<-mean(predictTest$class_ROC[predictTest$Default=="No"]=="No")
TPR<-mean(predictTest$class_ROC[predictTest$Default=="Si"]=="Si")
plot(rfROC)
FPR<-mean(predictTest$class_ROC[predictTest$Default=="No"]=="No")
TPR<-mean(predictTest$class_ROC[predictTest$Default=="Si"]=="Si")
plot(rfROC)
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
predictTest <- predictTest  %>%
mutate(class_ROC_2 = factor(ifelse(p_hat_ROC>.2,"Si","No"),levels=c("Si","No"))
)
confusionMatrix(data = predictTest$class_ROC_2, reference=predictTest$Default)
FPR_2<-mean(predictTest$class_ROC_2[predictTest$Default=="No"]=="No")
TPR_2<-mean(predictTest$class_ROC_2[predictTest$Default=="Si"]=="Si")
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
## our .5 rule cutoff
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
## A .2 rule cutoff
points(x= FPR_2,
y=TPR_2,
cex=4, pch=20, col='blue')
#Closest to top left cutoff
rfThresh <- coords(rfROC, x = "best", best.method = "closest.topleft")
rfThresh
predictTest <- predictTest  %>%
mutate(class_ROC_Thresh = factor(ifelse(p_hat_ROC>rfThresh$threshold,"Si","No"),levels=c("Si","No")) #en base al resultado anterior, pongo el threshold.
)
confusionMatrix(data = predictTest$class_ROC_Thresh, reference=predictTest$Default)
FPR_3<-mean(predictTest$class_ROC_Thresh[predictTest$Default=="No"]=="No")
TPR_3<-mean(predictTest$class_ROC_Thresh[predictTest$Default=="Si"]=="Si")
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
## our .5 rule cutoff
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
## A optimal threshold
points(x= FPR_3,
y=TPR_3,
cex=4, pch=20, col='green')
setwd("users/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("user/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("Users/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("User/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret, dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
#vemos que hay en el directorio de stores
dir("../stores")
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#vemos variables
names(train)
#renombramos variable Pobre a pobre
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
table(train$pobre) #los datos estan desbalanceados
glimpse(train)
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"), labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"), labels = c("No", "Si"))
#Correlation matrix
numeric_train <- train %>% select_if(is.numeric) #separamos las numericas
numeric_train <- ungroup(numeric_train) %>% select(-id)
cor_matrix <- cor(numeric_train) #calculamos correlacion
print(cor_matrix)
#Logit
ctrl<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
number = 10, #mejor 10. no sirve para dato espaciales
classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
verbose=FALSE,
savePredictions = T) #que guarde las predicciones
ctrl2<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
number = 10, #mejor 10. no sirve para dato espaciales
classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
verbose=FALSE,
savePredictions = T,
summaryFunction = twoClassSummary
)
set.seed(2023)
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.865, 0.01), # iremos variando los valores
lambda = seq(0, 0.05, 0.001)) # iremos variando los valores
colnames(hyperparameter_grid) <- c("alpha", "lambda")
set.seed(2023)
logit2 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit2
plot(logit2$results$lambda,
logit2$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
#Adaptamos hiperparámetros en base a esto
logit1$bestTune
logit2$bestTune
logit2
#Logit2
predictTest_logit2 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit2, type = "prob"),         ## predicted class probabilities
pred = predict(logit2, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit2)
confusionMatrix(data = predictTest_logit2$pred, reference=predictTest_logit2$obs)
#Evaluando los cortes/thresholds
roc_data <- roc(predictTest_logit2$obs, predictTest_logit2$Si)
plot(roc_data, main = "ROC Curve", col = "purple", lwd = 2) #vemos nuestra curva ROC. Estamos muy alto en sensitivity y bajo en specificity
mycoords <- coords(roc_data, "all")
plot(mycoords$threshold, mycoords$sensitivity, type = "l", col = "red",
xlab = "Cutoff", ylab = "Sensitivity", main = "Sensitivity vs. Cutoff")
lines(mycoords$threshold, mycoords$specificity, col = "blue")
legend("bottomright", legend = c("Sensitivity", "Specificity"), col = c("red", "blue"), lwd = 2)
#Nueva matiz
predicted_probabilities <- predictTest_logit2$Si
new_cutoff<-0.35
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.860, 0.001), # iremos variando los valores
lambda = seq(0, 0.05, 0.001)) # iremos variando los valores
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.860, 0.001), # iremos variando los valores
lambda = seq(0, 0.03, 0.001)) # iremos variando los valores
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.860, 0.001), # iremos variando los valores
lambda = seq(0, 0.03, 0.0001)) # iremos variando los valores
View(train)
#LOGIT3
set.seed(2023)
inTrain <- createDataPartition(
y = train$pobre.Si,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
#LOGIT3
set.seed(2023)
inTrain <- createDataPartition(
y = train$pobre,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
View(inTrain)
tr<-train[inTrain,]
ts<-train[-inTrain,]
View(tr)
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.860, 0.001), # iremos variando los valores
lambda = seq(0, 0.03, 0.0001)) # iremos variando los valores
logit3 <- tr(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = tr,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
logit3 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = tr,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.860, 0.001), # iremos variando los valores
lambda = seq(0, 0.03, 0.001)) # iremos variando los valores
set.seed(2023)
logit3 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = tr,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit2
plot(logit3$results$lambda,
logit3$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit3$bestTune
logit3
View(ts)
#Logit3
predictTest_logit3 <- data.frame(
obs = ts$pobre,                    ## observed class labels
predict(logit3, newdata=ts, type = "prob"),         ## predicted class probabilities
pred = predict(logit3, newdata=ts, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
View(predictTest_logit3)
head(predictTest_logit)
head(predictTest_logit3)
confusionMatrix(data = predictTest_logit3$pred, reference=predictTest_logit3$obs)
#Evaluando los cortes/thresholds
roc_data2 <- roc(predictTest_logit3$obs, predictTest_logit3$Si)
plot(roc_data2, main = "ROC Curve", col = "purple", lwd = 2) #vemos nuestra curva ROC. Estamos muy alto en sensitivity y bajo en specificity
mycoords <- coords(roc_data2, "all")
plot(mycoords2$threshold, mycoords2$sensitivity, type = "l", col = "red",
xlab = "Cutoff", ylab = "Sensitivity", main = "Sensitivity vs. Cutoff")
mycoords2 <- coords(roc_data2, "all")
plot(mycoords2$threshold, mycoords2$sensitivity, type = "l", col = "red",
xlab = "Cutoff", ylab = "Sensitivity", main = "Sensitivity vs. Cutoff")
lines(mycoords2$threshold, mycoords2$specificity, col = "blue")
legend("bottomright", legend = c("Sensitivity", "Specificity"), col = c("red", "blue"), lwd = 2)
#Nueva matiz
predicted_probabilities <- predictTest_logit3$Si
new_cutoff<-0.25
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.6
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.7
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.45
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.4
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.55
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.6
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.54
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.53
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.52
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.525
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.528
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
new_cutoff<-0.525
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
rm(tr)
rm(ts)
View(train)
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.85, 0.86, 0.01), # iremos variando los valores
lambda = seq(0, 0.02, 0.001)) # iremos variando los valores
#LOGIT3
set.seed(2023)
logit3 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = tr,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
logit3 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit3
plot(logit3$results$lambda,
logit3$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit3$bestTune
logit3
#Logit3
predictTest_logit3 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit3, type = "prob"),         ## predicted class probabilities
pred = predict(logit3, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit3)
confusionMatrix(data = predictTest_logit3$pred, reference=predictTest_logit3$obs)
View(predictTest_logit3)
#Evaluando los cortes/thresholds
roc_data <- roc(predictTest_logit3$obs, predictTest_logit3$Si)
plot(roc_data, main = "ROC Curve", col = "purple", lwd = 2) #vemos nuestra curva ROC. Estamos muy alto en sensitivity y bajo en specificity
mycoords <- coords(roc_data, "all")
plot(mycoords$threshold, mycoords$sensitivity, type = "l", col = "red",
xlab = "Cutoff", ylab = "Sensitivity", main = "Sensitivity vs. Cutoff")
lines(mycoords$threshold, mycoords$specificity, col = "blue")
legend("bottomright", legend = c("Sensitivity", "Specificity"), col = c("red", "blue"), lwd = 2)
#Nueva matiz
predicted_probabilities <- predictTest_logit2$Si
#Nueva matiz
predicted_probabilities <- predictTest_logit3$Si
new_cutoff<-0.45
predictTest_logit3$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit3$new_thres, reference=predictTest_logit3$obs)
confusionMatrix(data = predictTest_logit3$pred, reference=predictTest_logit3$obs)
# Logit3: Exporto la predicción en csv para cargar en Kaggle
test$pobre <- predict(logit3, newdata = test) #adaptamos
test_logit2 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test_logit3$pobre <- ifelse(test_logit3$pobre == "No", 0, 1)
test_logit3 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test_logit3$pobre <- ifelse(test_logit3$pobre == "No", 0, 1)
head(test_logit3) #evalúo que la base esté correctamente creada
write.csv(test_logit3,"../stores/logit3.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle
#LOGIT4
set.seed(2023)
logit4 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ v.cabecera* Jefe_mujer+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit3
plot(logit4$results$lambda,
logit4$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit4$bestTune
logit4
#Logit4
predictTest_logit4 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit4, type = "prob"),         ## predicted class probabilities
pred = predict(logit4, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit4)

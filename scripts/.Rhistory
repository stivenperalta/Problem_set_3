train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
names(train)
summary(train)
prop.table(table(train$d_arriendo))
glimpse(train)
View(train)
#convertimos en factor
as.factor(train$Regimen_salud)
summary(train)
#convertimos en factor
train$Regimen_salud <- as.factor(train$Regimen_salud)
summary(train)
test$Regimen_salud <- as.factor(test$Regimen_salud)
names(train)
summary(train)
train$Antiguedad_trabajo <- as.factor(train$Antiguedad_trabajo)
test$Antiguedad_trabajo <- as.factor(test$Antiguedad_trabajo)
summary(train)
names(train)
# selecciono variables de mayor interés
train <- select(train, c(1:6, 13:14, 16, 17, 19:24, 26, 44, 47, 48, 8, 9))
test <- select(test, c(1:6, 13:14, 16, 17, 19:24, 26, 44, 47, 48, 8, 9))
summary(train)
table(train$Li)
# Creo control por valicación cruzadamod_fr_1$bestTune
cv<-trainControl(method="cv",
number=5,
classProbs=TRUE, #retorna la probabilidad de cada una de las clases
verbose=TRUE, #
savePredictions=T) #que guarde las predicciones
names(train)
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train_1,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train,
method = "ranger",
trControl = cv,
maximize = F
)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train,
method = "rpart",
trControl = cv
)
# random forest clasificación
mod_rf_1 <- train(
pobre ~ . - id - IngresoPerCapita -Li -Lp,
data = train,
method = "ranger",
trControl = cv,
maximize = F,
metric = "Accuracy"
)
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC, randomForest, caret) # Cargar paquetes requeridos
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC, randomForest) # Cargar paquetes requeridos
# Creo control por valicación cruzadamod_fr_1$bestTune
cv<-trainControl(method="cv",
number=5)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ . - id - pobre -Li -Lp,
data = train,
method = "rpart",
trControl = cv
)
names(train)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + nper + Nivel_educativo + Tipodevivienda, #- id - pobre -Li -Lp
data = train,
method = "rpart",
trControl = cv
)
summary(train)
# random forest regresión
mod_rf_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + nper + Nivel_educativo + Tipodevivienda, #- id - pobre -Li -Lp
data = train,
method = "rpart"
#  trControl = cv
)
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
dplyr, tidyr, glmnet, pROC, randomForest) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
#convertimos en factor
train$Regimen_salud <- as.factor(train$Regimen_salud)
test$Regimen_salud <- as.factor(test$Regimen_salud)
# Evalúo la correlación de las variables (Matríz de correlación)
numeric_train <- train %>% select_if(is.numeric) #separamos las numericas
numeric_train <- ungroup(numeric_train) %>% select(-id)
cor_matrix <- cor(numeric_train) #calculamos correlacion
print(cor_matrix)
library(corrplot)
corrplot(cor_matrix, method = "circle", tl.col = "black")
rm(cor_matrix, numeric_train)
# Selecciono las variables para emplear en el modelo
names(train)
summary(train)
# selecciono variables de mayor interés
train <- select(train, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
test <- select(test, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
summary(train)
# convierto la variable pobre en factor y la ajusto con valores de 1 y 0
train$pobre <- as.factor(train$pobre)
test$pobre <- as.factor(test$pobre)
#Creo las bases para poder hacer las predicciones
test_relevant <- test %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
train_prueba <- train %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
#Balanceo la muestra para nivelar con el valor de menor frecuencia
set.seed(201718234)
down_train <- downSample(x = train[, -ncol(train)],
y = train$pobre)
table(down_train$pobre)
#Balanceo la muestra para nivelar con el valor de mayor frecuencia
set.seed(201718234)
up_train <- upSample(x = train[, -ncol(train)],
y = train$pobre)
table(up_train$pobre)
# Creo los parámetros e hiperparámetros de ajuste del modelo -------------------
ctrl <- trainControl(method = "repeatedcv",
repeats = 5,
classProbs = TRUE, # guardar probabilidades
summaryFunction = twoClassSummary) # calcular métricas para accuracy
pacman::p_load("adabag") # Boosting (adaboost)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "adaboost.M1",
trControl = ctrl,
tuneGrid = expand.grid(
#    mfinal = c(135,145), # número de árboles que hará (iteraciones)
#   maxdepth = c(25, 26), # profundidad de los árboles
coeflearn = c("Breiman", "Freund") # tipo de coeficiente de aprendizaje / el paquete usa por default el de Breiman
)
)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "adaboost",
trControl = ctrl,
tuneGrid = expand.grid(
#    mfinal = c(135,145), # número de árboles que hará (iteraciones)
#   maxdepth = c(25, 26), # profundidad de los árboles
coeflearn = c("Breiman", "Freund") # tipo de coeficiente de aprendizaje / el paquete usa por default el de Breiman
)
)
pacman::p_load("adabag", "fastAdaboost") #Boosting (adaboost)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "adaboost.M1",
trControl = ctrl,
tuneGrid = expand.grid(
#    mfinal = c(135,145), # número de árboles que hará (iteraciones)
#   maxdepth = c(25, 26), # profundidad de los árboles
coeflearn = c("Breiman", "Freund") # tipo de coeficiente de aprendizaje / el paquete usa por default el de Breiman
)
)
pacman::p_load("adabag", "plyr") #Boosting (adaboost)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "adaboost.M1",
trControl = ctrl,
tuneGrid = expand.grid(
#    mfinal = c(135,145), # número de árboles que hará (iteraciones)
#   maxdepth = c(25, 26), # profundidad de los árboles
coeflearn = c("Breiman", "Freund") # tipo de coeficiente de aprendizaje / el paquete usa por default el de Breiman
)
)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "adaboost",
trControl = ctrl,
tuneGrid = expand.grid(
#    mfinal = c(135,145), # número de árboles que hará (iteraciones)
#   maxdepth = c(25, 26), # profundidad de los árboles
coeflearn = c("Breiman", "Freund") # tipo de coeficiente de aprendizaje / el paquete usa por default el de Breiman
)
)
install.packages("fastAdaboost", dependencies = TRUE)
pacman::p_load("ada") #Boosting (adaboost)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "ada",
trControl = ctrl,
tuneGrid = expand.grid(
#    mfinal = c(135,145), # número de árboles que hará (iteraciones)
#   maxdepth = c(25, 26), # profundidad de los árboles
coeflearn = c("Breiman", "Freund") # tipo de coeficiente de aprendizaje / el paquete usa por default el de Breiman
)
)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "ada",
trControl = ctrl,
tuneGrid = expand.grid(
maxdepth = c(25, 26),
nu = c(0.1, 0.01),    # Shrinkage parameter (learning rate)
iter = c(100, 150),       # Number of boosting iterations
coeflearn = c("Breiman", "Freund") # tipo de coeficiente de aprendizaje / el paquete usa por default el de Breiman
)
)
# defino la grilla
grid <- expand.grid(
iter = c(100, 150),          # Number of boosting iterations
maxdepth = c(25, 26),        # Maximum tree depth
nu = c(0.1, 0.01),           # Shrinkage parameter (learning rate)
coeflearn = c("Breiman", "Freund")  # Learning coefficient
)
set.seed(201718234)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "ada",
trControl = ctrl,
tuneGrid = grid
)
# defino la grilla
grid <- expand.grid(
iter = c(100, 150),          # Number of boosting iterations
maxdepth = c(25, 26),        # Maximum tree depth
nu = c(0.1, 0.01),           # Shrinkage parameter (learning rate)
coeflearn = c("Breiman", "Freund")  # Learning coefficient
)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "ada",
trControl = ctrl,
tuneGrid = grid
)
# defino la grilla
grid <- expand.grid(
iter = c(100, 150),          # Number of boosting iterations
maxdepth = c(25, 26),        # Maximum tree depth
nu = c(0.1, 0.01)           # Shrinkage parameter (learning rate)
)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "ada",
trControl = ctrl,
tuneGrid = grid
)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = cv
)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl
)
# Creo control por valicación cruzadamod_fr_1$bestTune-------------------------
ctrl2<-trainControl(method="cv",
number=5)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
mod_en_1$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
varImp(mod_en_1)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + nper + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
mod_en_1$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
varImp(mod_en_1) # los resultados indican que es recomendable omitir d_arriendo, PersonasxCuarto y cuartos_hog
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
mod_en_1$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
varImp(mod_en_1) # los resultados indican que es recomendable omitir d_arriendo, PersonasxCuarto y cuartos_hog
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
verboseIter = 2
)
# Elastic Net regresión
library(progress)
with_progress({
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
})
# Elastic Net regresión
pacman::p_load(progress)
with_progress({
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
})
# Elastic Net regresión
pacman::p_load(tictoc)
with_progress({
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
})
?tictoc
pb <- progress_bar$new(format = "[:bar] :percent ETA: :eta",
total = 5, clear = FALSE)
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
callback = function(data) pb$tick()
)
pb$close()
tic()
pb <- progress_bar$new(format = "[:bar] :percent ETA: :eta",
total = 5, clear = FALSE)
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
callback = function(data) pb$tick()
)
toc()
pb$close()
pb <- progress_estimated(5)
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
callback = function(data) pb$tick()
)
pb <- txtProgressBar(min = 0,      # Valor mínimo de la barra de progreso
max = n_iter, # Valor máximo de la barra de progreso
style = 3,    # Estilo de la barra (también style = 1 y style = 2)
width = 50,   # Ancho de la barra. Por defecto: getOption("width")
char = "=")   # Caracter usado para crear la barra
pb <- txtProgressBar(min = 0,      # Valor mínimo de la barra de progreso
max = 100, # Valor máximo de la barra de progreso
style = 3,    # Estilo de la barra (también style = 1 y style = 2)
width = 50,   # Ancho de la barra. Por defecto: getOption("width")
char = "=")   # Caracter usado para crear la barra

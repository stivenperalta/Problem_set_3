predict(class_arboles, newdata = test, type = "prob"),         ## predicted class probabilities
pred = predict(class_arboles, newdata = test, type = "raw")    ## predicted class labels
)
head(predictTest_arbol)
# Accuracy
mean(predictTest_arbol$obs==predictTest_arbol$pred)
p_load("rpart.plot")
prp(class_arboles$finalModel, under = TRUE, branch.lty = 2, yesno = 2, faclen = 0, varlen=15,tweak=1.2,clip.facs= TRUE,box.palette = "Greens",compress=FALSE,ycompress = FALSE)
#Bosques
set.seed(123)
class_bosques <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "ranger",
trControl = ctrl,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(15,30,45,60))
)
class_bosques <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "ranger",
trControl = ctrl,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8), #cualquier subconjunto es bagging
splitrule = "gini", #parta el arbol a traves de gini
min.node.size = c(15,30,45,60)) #controlamos la profundidad del arbol por el numero de obs minimo
)
class_bosques
predictTest_bosque <- data.frame(
obs = test$Default,                                    ## observed class labels
predict(class_bosques, newdata = test, type = "prob"),         ## predicted class probabilities
pred = predict(class_bosques, newdata = test, type = "raw")    ## predicted class labels
)
# Accuracy
mean(predictTest_bosque$obs==[predictTest_bosque$pred)
# Accuracy
mean(predictTest_bosque$obs==predictTest_bosque$pred)
#AdaBoost
p_load("adabag")
set.seed(123)
class_adaboost <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "AdaBoost.M1",
trControl = ctrl,
tuneGrid=expand.grid(
mfinal = c(50,100,150),
maxdepth = c(1,2,3),
coeflearn = c('Breiman','Freund'))
)
class_adaboost
class_adaboost <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
method = "AdaBoost.M1",
trControl = ctrl,
tuneGrid=expand.grid(
mfinal = c(50,100,150),
maxdepth = c(1,2,3),
coeflearn = c('Breiman','Freund'))
)
#Cargar librerías
require("pacman")
p_load("tidyverse")
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
#Cargar librerías
require("pacman")
p_load("tidyverse")
#Leer los datos
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
#mutacion de factores
credit<-credit %>% mutate(Default=factor(Default,levels=c(1,0),labels=c("Si","No")),
history=factor(history,levels=c("good","poor","terrible"),labels=c("buena","mala","terrible")),
foreign=factor(foreign,levels=c("foreign","german"),labels=c("extranjero","aleman")),
purpose=factor(purpose,levels=c("newcar","usedcar","goods/repair","edu", "biz" ),labels=c("auto_nuevo","auto_usado","bienes","educacion","negocios")))
head(credit)
prop.table(table(credit$Default))
## First, split the training set
set.seed(1011)
p_load("caret")
inTrain <- createDataPartition(
y = credit$Default,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
train <- credit[ inTrain,]
test  <- credit[-inTrain,]
ctrl<- trainControl(method = "cv", #cross validation
number = 5, #number of folds
classProbs = TRUE, #retorne la probabilidad de clases
savePredictions = T) #retorne predicciones
set.seed(123)
class_ranger <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "Accuracy", #especificamos que queremos que maximice accuracy
method = "ranger", #bosque
trControl = ctrl,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8), #numero de prodectores
splitrule = "gini", #usando la regla que divide arboles con gini
min.node.size = c(25,50,150,200,250)) #profundidad, número de observaciones en cada nodo (lo mínimo que tienen que tener). mientras más observaciones, menos profundo será el árbol
)
class_ranger
#ahora usamos el F^train (de validacoón cruzada) reemplazamos en los observados de la muestra de entrenamiento (xtrain)= retorna una probabilidad
#usamos la clasificación de bayes 1[p^>0.5]
predictSample <- train   %>%
mutate(hat_default = predict(class_ranger, newdata = train, type = "raw")    ## predicted class labels. type raw= clasificador de bayes. esto dentro de train
)  %>% select(Default,hat_default) #nos quedamos solo con el observado y predicho
head(predictSample)
#miramos resultados
confusionMatrix(data = predictSample$hat_default, reference=predictSample$Default)
# Accuracy (A MANO)
mean(predictSample$Default==predictSample$ hat_default)
#quiero predecir bien fuera de muestra
predictTest <- data.frame(
Default = test$Default,                                    ## observed class labels
hat_default = predict(class_ranger, newdata = test, type = "raw")    ## predicted class labels
)
confusionMatrix(data = predictTest$hat_default, reference=predictTest$Default)
ctrl2<- trainControl(method = "cv",
number = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE,
savePredictions = T)
set.seed(123)
class_ranger_sens <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "Sens", #antes poníamos accuracy, ahora cambiamos a sens
method = "ranger",
trControl = ctrl2,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(25,50,150,200,250))
)
class_ranger_sens
#pero yo lo quiero fuera de muestra
predictTest<- test   %>%
mutate(hat_default_sens = predict(class_ranger_sens, newdata = test, type = "raw")    ## predicted class labels
)  %>% select(Default,hat_default_sens)
confusionMatrix(data = predictTest$hat_default,reference=predictTest$Default)
class_ranger_ROC <- train(
Default~duration+amount+installment+age+history + purpose+foreign+rent,
data=train,
metric = "ROC", #area bajo la curva
method = "ranger",
trControl = ctrl2,
tuneGrid=expand.grid(
mtry = c(1,2,3,4,5,6,7,8),
splitrule = "gini",
min.node.size = c(25,50,150,200,250))
)
class_ranger_ROC
#phat ROC= prob hat(y=si|x)
predictTest <- predictTest  %>%
mutate(class_ROC = predict(class_ranger_ROC, newdata = test, type = "raw"), # predicted class labels
p_hat_ROC=predict(class_ranger_ROC, newdata = test, type = "prob")$Si,         ## predicted class probabilities#
Default_num=ifelse(Default=="No",0,1) #si default es no, reemplazamos por 0, sino, 1
)
head(predictTest)
confusionMatrix(data = predictTest$class_ROC, reference=predictTest$Default)
p_load("pROC")
rfROC <- roc(predictTest$Default, predictTest$p_hat_ROC, levels = rev(levels(predictTest$Default)))
rfROC
FPR<-mean(predictTest$class_ROC[predictTest$Default=="No"]=="No")
TPR<-mean(predictTest$class_ROC[predictTest$Default=="Si"]=="Si")
plot(rfROC)
FPR<-mean(predictTest$class_ROC[predictTest$Default=="No"]=="No")
TPR<-mean(predictTest$class_ROC[predictTest$Default=="Si"]=="Si")
plot(rfROC)
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
predictTest <- predictTest  %>%
mutate(class_ROC_2 = factor(ifelse(p_hat_ROC>.2,"Si","No"),levels=c("Si","No"))
)
confusionMatrix(data = predictTest$class_ROC_2, reference=predictTest$Default)
FPR_2<-mean(predictTest$class_ROC_2[predictTest$Default=="No"]=="No")
TPR_2<-mean(predictTest$class_ROC_2[predictTest$Default=="Si"]=="Si")
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
## our .5 rule cutoff
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
## A .2 rule cutoff
points(x= FPR_2,
y=TPR_2,
cex=4, pch=20, col='blue')
#Closest to top left cutoff
rfThresh <- coords(rfROC, x = "best", best.method = "closest.topleft")
rfThresh
predictTest <- predictTest  %>%
mutate(class_ROC_Thresh = factor(ifelse(p_hat_ROC>rfThresh$threshold,"Si","No"),levels=c("Si","No")) #en base al resultado anterior, pongo el threshold.
)
confusionMatrix(data = predictTest$class_ROC_Thresh, reference=predictTest$Default)
FPR_3<-mean(predictTest$class_ROC_Thresh[predictTest$Default=="No"]=="No")
TPR_3<-mean(predictTest$class_ROC_Thresh[predictTest$Default=="Si"]=="Si")
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
plot(rfROC, print.auc=TRUE,legacy.axes=TRUE)
## our .5 rule cutoff
points(x= FPR,
y=TPR,
cex=4, pch=20, col='red')
## A optimal threshold
points(x= FPR_3,
y=TPR_3,
cex=4, pch=20, col='green')
setwd("users/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("user/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("Users/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
setwd("User/jazminegaldos/Documents/Uniandes/02_Ciclo/Big Data/GitHub/repositorios/Problem_set_3/scripts")
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret) # Cargar paquetes requeridos
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, tidyverse, caret, dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
#vemos que hay en el directorio de stores
dir("../stores")
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#vemos variables
names(train)
#renombramos variable Pobre a pobre
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
table(train$pobre) #los datos estan desbalanceados
glimpse(train)
#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"), labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"), labels = c("No", "Si"))
#Logit
ctrl<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
number = 10, #mejor 10. no sirve para dato espaciales
classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
verbose=FALSE,
savePredictions = T) #que guarde las predicciones
set.seed(2023)
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.85, 0.87, 0.01), # iremos variando los valores
lambda = seq(0, 0.1, 0.01)) # iremos variando los valores
colnames(hyperparameter_grid) <- c("alpha", "lambda")
logit1 <- train(pobre~cuartos_hog+ cuartos_dorm + nper+ npersug+Li
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
+ocupado + desocupado+ inactivo, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit1
plot(logit1$results$lambda,
logit1$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
#Adaptamos hiperparámetros en base a esto
logit1$bestTune
predictTest_logit <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit1, type = "prob"),         ## predicted class probabilities
pred = predict(logit1, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit)
confusionMatrix(data = predictTest_logit$hat_default, reference=predictTest_logit$Default)
View(predictTest_logit)
View(predictTest_logit)
glimpse(predictTest_logit)
confusionMatrix(data = predictTest_logit$pred, reference=predictTest_logit$obs)
table(train$v.cabecera)
names(train)
setseed(2023)
set.seed(2023)
logit2 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit2
plot(logit2$results$lambda,
logit2$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit2$bestTune
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.865, 0.01), # iremos variando los valores
lambda = seq(0, 0.1, 0.01)) # iremos variando los valores
#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.865, 0.01), # iremos variando los valores
lambda = seq(0, 0.05, 0.001)) # iremos variando los valores
logit2 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
+ d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
+ Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
+ fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
data = train,
metric="Accuracy", #metrica de performance
method = "glmnet", #logistic regression with elastic net regularization
trControl = ctrl,
tuneGrid = hyperparameter_grid,
family= "binomial"
)
#para tune logit2
plot(logit2$results$lambda,
logit2$results$Accuracy,
xlab="lambda",
ylab="Accuracy")
logit2$bestTune
#Logit2
predictTest_logit2 <- data.frame(
obs = train$pobre,                    ## observed class labels
predict(logit2, type = "prob"),         ## predicted class probabilities
pred = predict(logit2, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)
head(predictTest_logit2)
confusionMatrix(data = predictTest_logit2$pred, reference=predictTest_logit2$obs)
pacman::p_load(ggplot2, tidyverse, caret, dplyr, tidyr, glmnet, pROC, ROCR) # Cargar paquetes requeridos
#Evaluando los cortes/thresholds
predicted_probabilities <- predictTest_logit2$Si
true_labels <- predictTest_logit2$obs
prediction_obj <- prediction(predicted_probabilities, true_labels)
perf <- performance(prediction_obj, measure = "tpr", x.measure = "fpr")
print(perf)
glimpse(prediction_obj)
cortes <- prediction(predicted_probabilities, true_labels)
perf <- performance(cortes, measure = "tpr", x.measure = "fpr")
perf
head(perf)
glimpse(cortes)
plot(perf, main = "ROC Curve", col = "blue")
#Evaluando los cortes/thresholds
confusionMatrix(table(predict(logit2, type="prob")[,"s"] >= 0.25,
dat$positive == "s"))
pacman::p_load(ggplot2, tidyverse, caret, dplyr, tidyr, glmnet, pROC, rlsens) # Cargar paquetes requeridos
install.packages("rlsens")
#Evaluando los cortes/thresholds
roc_data <- roc(predictTest_logit2$obs, predictTest_logit2$pred)
#Evaluando los cortes/thresholds
roc_data <- roc(predictTest_logit2$obs, predictTest_logit2$Si)
View(roc_data)
cutoffs <- seq(0.3, 0.8, by = 0.01)
sensitivity <- sensitivity(roc_data, thresholds = cutoffs)
specificity <- specificity(roc_data, thresholds = cutoffs)
glimpse(predictTest_logit2)
#Evaluando los cortes/thresholds
roc_data <- roc(predictTest_logit2$obs, predictTest_logit2$Si)
roc_coords <- coords(roc_data, "threshold", ret = "best", transpose = TRUE)
plot(roc_data, main = "ROC Curve", col = "blue", lwd = 2)
plot(roc_data, main = "ROC Curve", col = "blue", lwd = 2)
sen_logit <- sens(roc_data, thresholds = thresholds)
sensitivity_values <- roc_data$sensitivities[thresholds]
thresholds <- seq(0, 1, by = 0.01) #evaluaremos en estos cortes
sensitivity_values <- roc_data$sensitivities[thresholds]
specificity_values <- 1 - roc_data$specificities[thresholds]
plot(sensitivity_values, specificity_values, type = "l", col = "red", lwd = 2,
xlab = "Sensitivity", ylab = "Specificity", main = "Sensitivity vs. Specificity")
plot(sensitivity_values, specificity_values, type = "l", col = "red", lwd = 2,
xlab = "Sensitivity", ylab = "Specificity", main = "Sensitivity vs. Specificity")
glimpse(sesitivity_values)
glimpse(sensitivity_values)
glimpse(specificity_values)
glimpse(roc_data)
plot(1 - specificity_values, sensitivity_values, type = "l", col = "red", lwd = 2,
xlab = "1 - Specificity", ylab = "Sensitivity", main = "Sensitivity vs. 1 - Specificity")
thresholds <- seq(0, 1, by = 0.01) #evaluaremos en estos cortes
sensitivity_values <- roc_data$sensitivities[thresholds]
specificity_values <- 1 - roc_data$specificities[thresholds]
roc_df <- data.frame(Threshold = thresholds, Sensitivity = sensitivity_values, Specificity = specificity_values)
# Plot sensitivity vs. specificity using ggplot2
ggplot(roc_df, aes(x = 1 - Specificity, y = Sensitivity)) +
geom_line(color = "red", size = 1) +
labs(x = "1 - Specificity", y = "Sensitivity", title = "Sensitivity vs. 1 - Specificity")
plot(roc_data, main = "ROC Curve", col = "purple", lwd = 2) #vemos nuestra curva ROC. Estamos muy alto en sensitivity y bajo en specificity
# Plot sensitivity vs. specificity using ggplot2
ggplot(roc_df, aes(x = 1 - Specificity, y = Sensitivity)) +
geom_line(color = "red", linewidth = 1) +
labs(x = "1 - Specificity", y = "Sensitivity", title = "Sensitivity vs. 1 - Specificity")
mycoords<- coords(roc_data, "all")
plot(mycoords["threshold",], mycoords["specificity",], type="l",
col="red", xlab="Cutoff", ylab="Performance")
View(mycoords)
View(mycoords)
plot(mycoords$threshold, mycoords$sensitivity, type = "l", col = "red",
xlab = "Cutoff", ylab = "Sensitivity", main = "Sensitivity vs. Cutoff")
lines(mycoords$threshold, mycoords$specificity, col = "blue")
legend("bottomright", legend = c("Sensitivity", "Specificity"), col = c("red", "blue"), lwd = 2)
#Calculando Youden J statistic
#Youden's J = Sensitivity + Specificity - 1
youden_j <- roc_coords$sensitivities + roc_coords$specificities - 1
#Calculando Youden J statistic
#Youden's J = Sensitivity + Specificity - 1
youden_j <- mycoords$sensitivities + mycoords$specificities - 1
optimal_threshold <- mycoords$thresholds[which.max(youden_j)]
optimal_threshold
glimpse(mycoords)
#Nueva matiz
logit_cutoff2 <- as.factor(ifelse(predict(logit2, type="raw")>0.25,"1","0"))
#Nueva matiz
logit_cutoff2 <- (ifelse(predict(logit2, type="raw")>0.25,"1","0")
#Nueva matiz
logit_cutoff2 <- (ifelse(predict(logit2, type="raw")>0.25,"1","0"))
#Nueva matiz
logit_cutoff2 <- (ifelse(predict(logit2, type="raw")>0.25,1,0))
logit_cutoff2 <- as.factor(ifelse(predict(logit2, type="raw")>0.25,"1","0"))
#Nueva matiz
logit_cutoff2 <- as.factor(ifelse(predict(logit2, type="prob")>0.25,"1","0"))
confusionMatrix(data = predictTest_logit2$pred, reference=predictTest_logit2$obs)
confusionMatrix(data = logit_cutoff2$pred, logit_cutoff2$obs)
glimpse(logit_cutoff2)
glimpse(predictTest_logit2)
#Nueva matiz
new_cutoff<-0.25
#Nueva matiz
predicted_probabilities <- predictTest_logit2$Si
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
View(predictTest_logit2)
View(predictTest_logit2)
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.20
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.25
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
# Exporto la predicción en csv para cargar en Kaggle
test$pobre <- predict(logit2, newdata = test) #adaptamos
test_logit2 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test_logit2$pobre <- ifelse(test_logit2$pobre == "No", 0, 1)
head(test_logit2) #evalúo que la base esté correctamente creada
write.csv(test_logit2,"../stores/logit2.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle
View(test)
View(test)
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.30
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.40
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.30
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.25
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
#Exporto prediccion con logit 2 pero con corte de 2.5
test$pobre <- predict(logit2, newdata = test, type="prob") #adaptamos
View(test)
View(test)
View(test)
test_logit2_1 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre$Si)
test_logit2_1 <- select(test$id, test$pobre$Si) #organizo el csv para poder cargarlo en kaggle
glimpse(test)
test$pobre <- test$pobre$Si
View(test)
test$pobre <- as.factor(ifelse(test$pobre > 0.25, "Si", "No"))
View(test)
test_logit2_1 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)test_logit2_1$pobre <- ifelse(test_logit2_1$pobre == "No", 0, 1)
test_logit2_1 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test_logit2_1$pobre <- ifelse(test_logit2_1$pobre == "No", 0, 1)
head(test_logit2_1) #evalúo que la base esté correctamente creada
write.csv(test_logit2_1,"../stores/logit2_1.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
confusionMatrix(data = predictTest_logit2$pred, reference=predictTest_logit2$obs)
new_cutoff<-0.30
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
confusionMatrix(data = predictTest_logit2$pred, reference=predictTest_logit2$obs)
new_cutoff<-0.35
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.40
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
new_cutoff<-0.35
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)
#Exporto prediccion con logit 2 pero con corte de 2.5
test$pobre <- predict(logit2, newdata = test, type="prob") #adaptamos
test$pobre <- test$pobre$Si
test$pobre <- as.factor(ifelse(test$pobre > 0.35, "Si", "No"))
test_logit2_1 <- test %>% #organizo el csv para poder cargarlo en kaggle
select(id,pobre)
test_logit2_1$pobre <- ifelse(test_logit2_1$pobre == "No", 0, 1)
head(test_logit2_1) #evalúo que la base esté correctamente creada
write.csv(test_logit2_1,"../stores/logit2_1.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle
confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)

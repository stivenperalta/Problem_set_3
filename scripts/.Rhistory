mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl
)
# Creo control por valicación cruzadamod_fr_1$bestTune-------------------------
ctrl2<-trainControl(method="cv",
number=5)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
mod_en_1$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
varImp(mod_en_1)
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + nper + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
mod_en_1$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
varImp(mod_en_1) # los resultados indican que es recomendable omitir d_arriendo, PersonasxCuarto y cuartos_hog
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
mod_en_1$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
varImp(mod_en_1) # los resultados indican que es recomendable omitir d_arriendo, PersonasxCuarto y cuartos_hog
# Elastic Net regresión
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
verboseIter = 2
)
# Elastic Net regresión
library(progress)
with_progress({
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
})
# Elastic Net regresión
pacman::p_load(progress)
with_progress({
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
})
# Elastic Net regresión
pacman::p_load(tictoc)
with_progress({
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2
)
})
?tictoc
pb <- progress_bar$new(format = "[:bar] :percent ETA: :eta",
total = 5, clear = FALSE)
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
callback = function(data) pb$tick()
)
pb$close()
tic()
pb <- progress_bar$new(format = "[:bar] :percent ETA: :eta",
total = 5, clear = FALSE)
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
callback = function(data) pb$tick()
)
toc()
pb$close()
pb <- progress_estimated(5)
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + Jefe_mujer +
Tipodevivienda + Educacion_promedio + sexo + edad + seg_soc +
Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
callback = function(data) pb$tick()
)
pb <- txtProgressBar(min = 0,      # Valor mínimo de la barra de progreso
max = n_iter, # Valor máximo de la barra de progreso
style = 3,    # Estilo de la barra (también style = 1 y style = 2)
width = 50,   # Ancho de la barra. Por defecto: getOption("width")
char = "=")   # Caracter usado para crear la barra
pb <- txtProgressBar(min = 0,      # Valor mínimo de la barra de progreso
max = 100, # Valor máximo de la barra de progreso
style = 3,    # Estilo de la barra (también style = 1 y style = 2)
width = 50,   # Ancho de la barra. Por defecto: getOption("width")
char = "=")   # Caracter usado para crear la barra
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
ada, # Adaboost para clasificación
dplyr, tidyr, glmnet, pROC, randomForest) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
#convertimos en factor
train$Regimen_salud <- as.factor(train$Regimen_salud)
test$Regimen_salud <- as.factor(test$Regimen_salud)
# Evalúo la correlación de las variables (Matríz de correlación)
numeric_train <- train %>% select_if(is.numeric) #separamos las numericas
numeric_train <- ungroup(numeric_train) %>% select(-id)
cor_matrix <- cor(numeric_train) #calculamos correlacion
print(cor_matrix)
library(corrplot)
corrplot(cor_matrix, method = "circle", tl.col = "black")
rm(cor_matrix, numeric_train)
# Selecciono las variables para emplear en el modelo
names(train)
summary(train)
# selecciono variables de mayor interés
train <- select(train, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
test <- select(test, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
summary(train)
# convierto la variable pobre en factor y la ajusto con valores de 1 y 0
train$pobre <- as.factor(train$pobre)
test$pobre <- as.factor(test$pobre)
#Creo las bases para poder hacer las predicciones
test_relevant <- test %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
train_prueba <- train %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
#Balanceo la muestra para nivelar con el valor de menor frecuencia
set.seed(201718234)
down_train <- downSample(x = train[, -ncol(train)],
y = train$pobre)
table(down_train$pobre)
#Balanceo la muestra para nivelar con el valor de mayor frecuencia
set.seed(201718234)
up_train <- upSample(x = train[, -ncol(train)],
y = train$pobre)
table(up_train$pobre)
# Creo los parámetros e hiperparámetros de ajuste del modelo -------------------
ctrl <- trainControl(method = "repeatedcv", # CV para clasificación
repeats = 5,
classProbs = TRUE, # guardar probabilidades
summaryFunction = twoClassSummary) # calcular métricas para accuracy
# defino la grilla
grid <- expand.grid(
iter = c(100, 150),          # Number of boosting iterations
maxdepth = c(25, 26),        # Maximum tree depth
nu = c(0.1, 0.01)           # Shrinkage parameter (learning rate)
)
set.seed(201718234)
mod_adaboost_1 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
metric = "Accuracy",
method = "ada",
trControl = ctrl,
tuneGrid = grid
)
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
ada, # Adaboost para clasificación
dplyr, tidyr, glmnet, pROC, randomForest) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
#convertimos en factor
train$Regimen_salud <- as.factor(train$Regimen_salud)
test$Regimen_salud <- as.factor(test$Regimen_salud)
# Evalúo la correlación de las variables (Matríz de correlación)
numeric_train <- train %>% select_if(is.numeric) #separamos las numericas
numeric_train <- ungroup(numeric_train) %>% select(-id)
cor_matrix <- cor(numeric_train) #calculamos correlacion
print(cor_matrix)
library(corrplot)
corrplot(cor_matrix, method = "circle", tl.col = "black")
rm(cor_matrix, numeric_train)
# Selecciono las variables para emplear en el modelo
names(train)
summary(train)
# selecciono variables de mayor interés
train <- select(train, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
test <- select(test, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
summary(train)
# convierto la variable pobre en factor y la ajusto con valores de 1 y 0
train$pobre <- as.factor(train$pobre)
test$pobre <- as.factor(test$pobre)
#Creo las bases para poder hacer las predicciones
test_relevant <- test %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
train_prueba <- train %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
#Balanceo la muestra para nivelar con el valor de menor frecuencia
set.seed(201718234)
down_train <- downSample(x = train[, -ncol(train)],
y = train$pobre)
table(down_train$pobre)
#Balanceo la muestra para nivelar con el valor de mayor frecuencia
set.seed(201718234)
up_train <- upSample(x = train[, -ncol(train)],
y = train$pobre)
table(up_train$pobre)
# Creo los parámetros e hiperparámetros de ajuste del modelo -------------------
ctrl <- trainControl(method = "repeatedcv", # CV para clasificación
repeats = 5,
classProbs = TRUE, # guardar probabilidades
summaryFunction = twoClassSummary) # calcular métricas para accuracy
# defino la grilla
grid <- expand.grid(
iter = c(40, 50),          # Number of boosting iterations
maxdepth = c(15),        # Maximum tree depth
nu = c(0.1, 0.01)           # Shrinkage parameter (learning rate)
)
# Creo control por valicación cruzada para regresión ---------------------------
ctrl2<-trainControl(method="cv",
number=5,
savePredictions= TRUE) #que guarde las predicciones
#creo la grilla para random forest
tunegrid_rf <- expand.grid(
min.node.size = seq(c(135,145,length.out=5)), # controla la profundidad del árbol
mtry = c(25, 26), #sqrt de variables # es el número de predictores (si los toma todos es bagging; solo un subconjunto es random forest)
splitrule = "gini" # empleamos el índice de gini como regla de partición
)
#creo la grilla para random forest
tunegrid_rf <- expand.grid(
min.node.size = seq(c(135,145,length.out=5)), # controla la profundidad del árbol
mtry = c(25, 26), #sqrt de variables # es el número de predictores (si los toma todos es bagging; solo un subconjunto es random forest)
splitrule = "gini" # empleamos el índice de gini como regla de partición
)
#creo la grilla para random forest
tunegrid_rf <- expand.grid(
min.node.size = seq(c(10,150,length.out=5)), # controla la profundidad del árbol
mtry = c(5, 8, 15), #sqrt de variables # es el número de predictores (si los toma todos es bagging; solo un subconjunto es random forest)
splitrule = "gini" # empleamos el índice de gini como regla de partición
)
rm(list = ls()) # Limpiar Rstudio
pacman::p_load(ggplot2, #gráficas
tidyverse, #limpieza
caret, #modelos
parallel, # conocer los cores de mi pc
doParallel, # maximizar el procesamiento en r en función de los cores de mi pc
ranger,
ada, # Adaboost para clasificación
dplyr, tidyr, glmnet, pROC, randomForest) # Cargar paquetes requeridos
#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script)
setwd(path_folder)
getwd()
rm(path_folder, path_script)
# maximizo el procesamiento de r
detectCores() # detecta los cores del computador
registerDoParallel(6) # 6 de 8 cores de mi computador para R
getDoParWorkers() # verifico el número de cores usados por R
#vemos que hay en el directorio de stores
dir("../stores")
#Importamos las bases
test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")
#renombramos variable Pobre a pobre (para poder cargarla en kaggle)
test <- test %>%
rename(pobre = Pobre)
train <- train %>%
rename(pobre=Pobre)
prop.table(table(train$pobre)) #los datos estan desbalanceados
#Mutación de factores (tenemos que hacerlo por niveles/levels)
test$pobre <- factor(test$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
train$pobre <- factor(train$pobre, levels = c("0", "1"),
labels = c("No", "Si"))
#convertimos en factor
train$Regimen_salud <- as.factor(train$Regimen_salud)
test$Regimen_salud <- as.factor(test$Regimen_salud)
# Evalúo la correlación de las variables (Matríz de correlación)
numeric_train <- train %>% select_if(is.numeric) #separamos las numericas
numeric_train <- ungroup(numeric_train) %>% select(-id)
cor_matrix <- cor(numeric_train) #calculamos correlacion
print(cor_matrix)
library(corrplot)
corrplot(cor_matrix, method = "circle", tl.col = "black")
rm(cor_matrix, numeric_train)
# Selecciono las variables para emplear en el modelo
names(train)
summary(train)
# selecciono variables de mayor interés
train <- select(train, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
test <- select(test, c(1:4, 6, 13:14, 16, 17, 19:23, 26, 44, 47, 48, 8, 9))
summary(train)
# convierto la variable pobre en factor y la ajusto con valores de 1 y 0
train$pobre <- as.factor(train$pobre)
test$pobre <- as.factor(test$pobre)
#Creo las bases para poder hacer las predicciones
test_relevant <- test %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
train_prueba <- train %>%
ungroup() %>%
select(Porcentaje_ocupados, v.cabecera, cuartos_hog, nper,
d_arriendo, Jefe_mujer, PersonaxCuarto, Tipodevivienda,
Educacion_promedio, sexo, edad, seg_soc, Nivel_educativo,
Tipo_de_trabajo, ocupado, IngresoPerCapita, pobre)
#Balanceo la muestra para nivelar con el valor de menor frecuencia
set.seed(201718234)
down_train <- downSample(x = train[, -ncol(train)],
y = train$pobre)
table(down_train$pobre)
#Balanceo la muestra para nivelar con el valor de mayor frecuencia
set.seed(201718234)
up_train <- upSample(x = train[, -ncol(train)],
y = train$pobre)
table(up_train$pobre)
# Creo control por valicación cruzada para clasificación
ctrl <- trainControl(method = "repeatedcv", # CV para clasificación
repeats = 5,
classProbs = TRUE, # guardar probabilidades
summaryFunction = twoClassSummary) # calcular métricas para accuracy
# defino la grilla
grid <- expand.grid(
iter = c(40, 50),          # Number of boosting iterations
maxdepth = c(15),        # Maximum tree depth
nu = c(0.1, 0.01)           # Shrinkage parameter (learning rate)
)
# Creo control por valicación cruzada para regresión
ctrl2<-trainControl(method="cv",
number=5,
savePredictions= TRUE) #que guarde las predicciones
#creo la grilla para random forest
tunegrid_rf <- expand.grid(
min.node.size = seq(c(10,150,length.out=5)), # controla la profundidad del árbol
mtry = c(5, 8, 15), #sqrt de variables # es el número de predictores (si los toma todos es bagging; solo un subconjunto es random forest)
splitrule = "gini" # empleamos el índice de gini como regla de partición
)
# Elastic Net regresión con data desbalanceada
mod_en_1 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = train,
method = "glmnet",
trControl = ctrl2,
metric = "MAE",
tuneGrid = expand.grid(alpha = seq(0.6, 0.9, length.out =5),
lambda = seq(862.3046, 867.3046, length.out =10))
)
mod_en_1$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
#Evalúo la predicción dentro de muestra
train_prueba$ingreso <- predict(mod_en_1, newdata = train_prueba)
train_prueba$pred_pobre <- ifelse(train_prueba$ingreso>train$Li, 0, 1)
train_prueba$pobre <- ifelse(train_prueba$pobre == "Si", 1, 0)
train_prueba$pred_pobre <- factor(train_prueba$pred_pobre, levels = c(0, 1))
train_prueba$pobre <- factor(train_prueba$pobre, levels = c(0, 1))
conf_matrix <- confusionMatrix(train_prueba$pred_pobre, train_prueba$pobre)
print(conf_matrix) # observo la matriz de confusión
# Elastic Net regresión con data balanceada (upsample)
mod_en_3 <- train(
IngresoPerCapita ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = up_train,
method = "glmnet",
trControl = ctrl2,
metric = "MAE",
tuneGrid = expand.grid(alpha = seq(0.4, 0.7, length.out =5),
lambda = seq(70519.15, 74519.15, length.out =10))
)
mod_en_3$bestTune # Evalúo los mejores hiperparámetros para ajustar la grilla
varImp(mod_en_3)
#Evalúo la predicción dentro de muestra
train_prueba$ingreso_en_3 <- predict(mod_en_3, newdata = train_prueba)
train_prueba$pred_pobre <- ifelse(train_prueba$ingreso_en_3>train$Li, 0, 1)
train_prueba$pobre <- ifelse(train_prueba$pobre == "Si", 1, 0)
train_prueba$pred_pobre <- factor(train_prueba$pred_pobre, levels = c(0, 1))
train_prueba$pobre <- factor(train_prueba$pobre, levels = c(0, 1))
conf_matrix <- confusionMatrix(train_prueba$pred_pobre, train_prueba$pobre)
print(conf_matrix) # observo la matriz de confusión
# Elastic Net clasificación con balance downsample
mod_en_2 <- train(
pobre ~ Porcentaje_ocupados + v.cabecera + cuartos_hog + nper +
d_arriendo + Jefe_mujer + PersonaxCuarto + Tipodevivienda + Educacion_promedio +
sexo + edad + seg_soc + Nivel_educativo + Tipo_de_trabajo + ocupado,
data = down_train,
method = "glmnet",
trControl = cv,
metric = "Accuracy"#
)#,

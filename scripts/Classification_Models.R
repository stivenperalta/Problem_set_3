#Classification Models

# Preparación -------------------------------------------------------------

rm(list = ls()) # Limpiar Rstudio

pacman::p_load(ggplot2, tidyverse, caret, dplyr, tidyr, glmnet, pROC) # Cargar paquetes requeridos

#Definir el directorio
path_script<-rstudioapi::getActiveDocumentContext()$path
path_folder<-dirname(path_script) 
setwd(path_folder)
getwd()

#vemos que hay en el directorio de stores
dir("../stores")

test<-readRDS("../stores/test_final.rds")
train<-readRDS("../stores/train_final.rds")

#vemos variables
names(train)

#renombramos variable Pobre a pobre
test <- test %>%
  rename(pobre = Pobre)
train <- train %>%
  rename(pobre=Pobre)

table(train$pobre) #los datos estan desbalanceados
glimpse(train)

#Mutación de factores (tenemos que hacerlo por niveles/levels)
train$pobre <- factor(train$pobre, levels = c("0", "1"), labels = c("No", "Si"))
test$pobre <- factor(test$pobre, levels = c("0", "1"), labels = c("No", "Si"))


#Correlation matrix
numeric_train <- train %>% select_if(is.numeric) #separamos las numericas
numeric_train <- ungroup(numeric_train) %>% select(-id)

cor_matrix <- cor(numeric_train) #calculamos correlacion
print(cor_matrix)

# LOGIT  -------------------------------------------------------------------

#Logit
ctrl<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
                    number = 10, #mejor 10. no sirve para dato espaciales
                    classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
                    verbose=FALSE,
                    savePredictions = T) #que guarde las predicciones

ctrl2<- trainControl(method = "cv", #controla el entrenamiento, la validacion cruzada.
                     number = 10, #mejor 10. no sirve para dato espaciales
                     classProbs = TRUE, #probabilidad de las clases en lugar de raw predicciones
                     verbose=FALSE,
                     savePredictions = T,
                     summaryFunction = twoClassSummary
                     )

set.seed(2023)

#hacemos la grilla para los hiperparámetros
hyperparameter_grid <- expand.grid(alpha = seq(0.855, 0.865, 0.01), # iremos variando los valores
                                   lambda = seq(0, 0.05, 0.001)) # iremos variando los valores


colnames(hyperparameter_grid) <- c("alpha", "lambda")

logit1 <- train(pobre~cuartos_hog+ cuartos_dorm + nper+ npersug+Li
                + d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
                + Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
                +ocupado + desocupado+ inactivo, #especifico mi formula. primero utilizaremos todos los predictores "."
                data = train,
                metric="Accuracy", #metrica de performance
                method = "glmnet", #logistic regression with elastic net regularization
                trControl = ctrl,
                tuneGrid = hyperparameter_grid,
                family= "binomial"
)

#para tune logit1
plot(logit1$results$lambda,
     logit1$results$Accuracy,
     xlab="lambda",
     ylab="Accuracy")

set.seed(2023)
logit2 <- train(pobre~Porcentaje_ocupados+ + v.cabecera+ cuartos_hog + nper+ npersug
                + d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
                + Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ Tipo_de_trabajo+otro_trab
                + fondo_pensiones +ocupado, #especifico mi formula. primero utilizaremos todos los predictores "."
                data = train,
                metric="Accuracy", #metrica de performance
                method = "glmnet", #logistic regression with elastic net regularization
                trControl = ctrl,
                tuneGrid = hyperparameter_grid,
                family= "binomial"
)

#para tune logit2
plot(logit2$results$lambda,
     logit2$results$Accuracy,
     xlab="lambda",
     ylab="Accuracy")


# LOGIT BESTUNES ----------------------------------------------------------

#Adaptamos hiperparámetros en base a esto
logit1$bestTune
logit2$bestTune

logit1
logit2



# Cambiando cortes para Logit ---------------------------------------------


#Logit1
predictTest_logit <- data.frame(
  obs = train$pobre,                    ## observed class labels
  predict(logit1, type = "prob"),         ## predicted class probabilities
  pred = predict(logit1, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)

head(predictTest_logit)

confusionMatrix(data = predictTest_logit$pred, reference=predictTest_logit$obs)

#Logit2
predictTest_logit2 <- data.frame(
  obs = train$pobre,                    ## observed class labels
  predict(logit2, type = "prob"),         ## predicted class probabilities
  pred = predict(logit2, type = "raw")    ## predicted class labels (esto luego lo sacamos porque vamos a variar el corte)
)

head(predictTest_logit2)

confusionMatrix(data = predictTest_logit2$pred, reference=predictTest_logit2$obs)

#Evaluando los cortes/thresholds
roc_data <- roc(predictTest_logit2$obs, predictTest_logit2$Si)
plot(roc_data, main = "ROC Curve", col = "purple", lwd = 2) #vemos nuestra curva ROC. Estamos muy alto en sensitivity y bajo en specificity
mycoords <- coords(roc_data, "all")

plot(mycoords$threshold, mycoords$sensitivity, type = "l", col = "red",
     xlab = "Cutoff", ylab = "Sensitivity", main = "Sensitivity vs. Cutoff")
lines(mycoords$threshold, mycoords$specificity, col = "blue")
legend("bottomright", legend = c("Sensitivity", "Specificity"), col = c("red", "blue"), lwd = 2)

#Nueva matiz
predicted_probabilities <- predictTest_logit2$Si
new_cutoff<-0.25
predictTest_logit2$new_thres <- factor(ifelse(predicted_probabilities > new_cutoff, "Si", "No"))

confusionMatrix(data = predictTest_logit2$new_thres, reference=predictTest_logit2$obs)


#Calculando Youden J statistic
#Youden's J = Sensitivity + Specificity - 1
#youden_j <- mycoords$sensitivities + mycoords$specificities - 1
#optimal_threshold <- mycoords$thresholds[which.max(youden_j)]

#optimal_threshold

# Predicción Kaggle LOGIT -------------------------------------------------


# Exporto la predicción en csv para cargar en Kaggle
test$pobre <- predict(logit1, newdata = test) #adaptamos 
test_logit1 <- test %>% #organizo el csv para poder cargarlo en kaggle
  select(id,pobre)
test_logit1$pobre <- ifelse(test_logit1$pobre == "No", 0, 1)
head(test_logit1) #evalúo que la base esté correctamente creada
write.csv(test_logit1,"../stores/test_logit1.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle

# Exporto la predicción en csv para cargar en Kaggle
test$pobre <- predict(logit2, newdata = test) #adaptamos 
test_logit2 <- test %>% #organizo el csv para poder cargarlo en kaggle
  select(id,pobre)
test_logit2$pobre <- ifelse(test_logit2$pobre == "No", 0, 1)
head(test_logit2) #evalúo que la base esté correctamente creada
write.csv(test_logit2,"../stores/logit2.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle

#Exporto prediccion con logit 2 pero con corte de 2.5
test$pobre <- predict(logit2, newdata = test, type="prob") #adaptamos 
test_logit2_1 <- test %>% #organizo el csv para poder cargarlo en kaggle
  select(id,pobre)
test_logit2_1$pobre <- ifelse(test_logit2_1$pobre == "No", 0, 1)
head(test_logit2) #evalúo que la base esté correctamente creada
write.csv(test_logit2_1,"../stores/logit2_1.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle





# LDA -------------------------------------

set.seed(1234)

lda_1 = train(pobre~cuartos_hog+ nper+Li #saco npersug y cuartos hogar porque tiene muy alta correlacion con nper
              + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
              + Educacion_promedio +edad+ seg_soc+ Nivel_educativo+ otro_trab
              +ocupado, 
              data=train, 
              method="lda",
              trControl = ctrl,
              metric="Accuracy")

lda_1

# Exporto la predicción en csv para cargar en Kaggle
test$pobre <- predict(lda_1, newdata = test) #adaptamos 
test_lda <- test %>% #organizo el csv para poder cargarlo en kaggle
  select(id,pobre)
test_lda$pobre <- ifelse(test_lda$pobre == "No", 0, 1)
head(test_lda) #evalúo que la base esté correctamente creada
write.csv(test_lda,"../stores/lda1.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle




# KNN ---------------------------------------------------------------------

set.seed(2009)
mylogit_knn <- train(pobre~cuartos_hog+ cuartos_dorm + nper+ npersug+Li
                     + d_arriendo + Jefe_mujer+ PersonaxCuarto+ Tipodevivienda
                     + Educacion_promedio + sexo +edad+ seg_soc+ Nivel_educativo+ otro_trab
                     +ocupado + desocupado+ inactivo, 
                     data = train, 
                     method = "knn",
                     trControl = ctrl,
                     tuneGrid = expand.grid(k=c(3,5,7,9,11))) #el mejor fue el 11


mylogit_knn

# Exporto la predicción en csv para cargar en Kaggle
test$pobre <- predict(mylogit_knn, newdata = test) #adaptamos 
test_knn <- test %>% #organizo el csv para poder cargarlo en kaggle
  select(id,pobre)
test_knn$pobre <- ifelse(test_knn$pobre == "No", 0, 1)
head(test_knn) #evalúo que la base esté correctamente creada
write.csv(test_knn,"../stores/knn1.csv",row.names=FALSE) # Exporto la predicción para cargarla en Kaggle


# Resultados de tune grid -------------------------------------------------

#LOGIT

#Logit 1
alpha lambda
37  0.86      0

Confusion Matrix and Statistics

Reference
Prediction     No     Si
No 125412  21862
Si   6524  11162

Accuracy : 0.8279          
95% CI : (0.8261, 0.8297)
No Information Rate : 0.7998          
P-Value [Acc > NIR] : < 2.2e-16       

Kappa : 0.3494          

Mcnemar's Test P-Value : < 2.2e-16       
                                          
            Sensitivity : 0.9506          
            Specificity : 0.3380          
         Pos Pred Value : 0.8516          
         Neg Pred Value : 0.6311          
             Prevalence : 0.7998          
         Detection Rate : 0.7603          
   Detection Prevalence : 0.8928          
      Balanced Accuracy : 0.6443          
                                          
       'Positive' Class : No  ' 

#Logit2

> logit2$bestTune
   alpha lambda
53 0.865  0.001

Confusion Matrix and Statistics

Reference
Prediction     No     Si
No 124452  16688
Si   7484  16336

Accuracy : 0.8535          
95% CI : (0.8518, 0.8552)
No Information Rate : 0.7998          
P-Value [Acc > NIR] : < 2.2e-16       

Kappa : 0.489           

Mcnemar's Test P-Value : < 2.2e-16       
                                          
            Sensitivity : 0.9433          
            Specificity : 0.4947          
         Pos Pred Value : 0.8818          
         Neg Pred Value : 0.6858          
             Prevalence : 0.7998          
         Detection Rate : 0.7544          
   Detection Prevalence : 0.8556          
      Balanced Accuracy : 0.7190          
                                          
       'Positive' Class : No  ' 

#Logit 2.1- con cutoff en 2.5

#KNN
Accuracy was used to select the optimal model using the largest value.
The final value used for the model was k = 11.

#LDA1
Linear Discriminant Analysis 

164960 samples
12 predictor
2 classes: 'No', 'Si' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 148464, 148464, 148463, 148465, 148465, 148464, ... 
Resampling results:
  
  Accuracy   Kappa   
0.8268247  0.360719